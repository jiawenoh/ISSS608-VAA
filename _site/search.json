[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\npacman::p_load(ggstatsplot, tidyverse,rstantools)\n\n\nImporting data\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visual-statistical-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visual-statistical-analysis",
    "title": "Hands-on Exercise 4",
    "section": "1) Visual Statistical Analysis",
    "text": "1) Visual Statistical Analysis\n\n1.1) One-sample test: gghistostats() method\nIn the below output, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nOutput:\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\n\n\n\n1.2) Two-sample mean test: ggbetweenstats()\nIn the below output, ggbetweenstats() is used to to build an visual of two-sample mean test.\n\nOutput:\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n1.3) One-way ANOVA Test: ggbetweenstats() method\nIn the below output, ggbetweenstats() is used to to build an visual of one-way ANOVA test.\n\nOutput:\n\nggbetweenstats(\n  data = exam_data, \n  x = RACE, \n  y = ENGLISH, \n  type = \"p\", \n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE,\n  #\"ns\" for only non-significant, \"s\" for only significant, \"all\" for everything\n  pairwise.display = \"s\",      \n  p.adjust.method = \"fdr\", \n  messages = FALSE \n  )\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n1.4) Significant Test of Correlation: ggscatterstats()\nIn the below output, ggscatterstats() is used to to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nOutput:\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n1.5) Significant Test of Association (Depedence) : ggbarstats() methods\nIn the below output, ggbarstats() is used to to build a visual for Significant Test of Association (Dependence).\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nOutput:\n\nexam1 <- exam_data |> \n  mutate(MATHS_bins =\n           cut(MATHS, \n               breaks = c(0, 60, 75, 85, 100)))\n\nIn this code chunk below, ggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(\n  data = exam1,\n  x = MATHS_bins,\n  y = GENDER\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "title": "Hands-on Exercise 4",
    "section": "2) Visualising Models",
    "text": "2) Visualising Models\n\n2.1) Getting Started\n\nUsing p_load() of pacman package to load the required libraries\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\nImporting data\n\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   <dbl> <chr>    <dbl>     <dbl>     <dbl>    <dbl>  <dbl>         <dbl>  <dbl>\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period <dbl>, HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>, …\n\n\nNote: car_resale is a tibble data frame.\n\n\n2.2) Multiple Regression Model using lm()\nIn the below output, lm() is used to calibrate a multiple linear regression model of Base Stats of R.\n\nOutput:\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\n2.3) Model Diagnostic: Checking for multicolinearity using check_collinearity()\nIn the below output, check_collinearity() is used to check for multicolinearity.\n\nOutput:\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\nAs per figure above, Age_08_04 and Mfg_Year are highly correlated.\nRemove/Drop Mfg_Year.\n\n\n\n2.3) Model Diagnostic: Checking for normality assumption using check_normality()\nIn the below output, check_normality() is used to check for normality assumption. #### Output:\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\nBased on the figure above, we will reject the Null hypothesis and infer that the model failed to conform to normaility assumption.\n\n\n2.4) Model Diagnostic: Checking model for homogeneity of variances using check_heteroscedasticity()\nIn the below output, check_heteroscedasticity() is used to check model for homogeneity of variances.\n\nOutput:\n\ncheck_h <- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n\n2.5) Model Diagnostic: Complete check using check_model()\nIn the below output, check_model() is used.\n\nOutput:\n\ncheck_model(model1)\n\n\n\n\n\n\n\n2.6) Visualising Regression Parameters\nIn the below output, plot() of see package and parameters() of parameters package are used to visualize the parameters of a regression model.\n\nOutput:\n\nplot(parameters(model1))\n\n\n\n\nIn the below output, ggcoefstats() of ggstatsplot package is used to visualize the parameters of a regression model.\n\n\nOutput:\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty",
    "title": "Hands-on Exercise 4",
    "section": "3) Visualising Uncertainty",
    "text": "3) Visualising Uncertainty\n\n3.1) Getting Started\n\nUsing p_load() of pacman package to load the required libraries\n\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate)\n\n\nImporting data\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\n\n3.2) Visualizing the uncertainty of point estimates of using ggplot2\nIn the below output, ggplot2 is used.\nIt performs group by RACE and compute by calculating the observation, mean, standard deviation, and standard error of MATHS score by RACE. Then, it saves the output as a tibble data table called my_sum.\n\nOutput:\n\nmy_sum <- exam_data |> \n  group_by(RACE) |> \n  summarize(\n    n = n(),\n    mean = mean(MATHS),\n    sd = sd(MATHS)) |>\n  mutate(se = sd/sqrt(n-1))\nmy_sum$RACE  <- fct_reorder(my_sum$RACE, my_sum$mean, .desc = TRUE)\n\nNext, the code chunk below will be shown in html format.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\n\n3.2.1 ) Reveal the standard error of mean Maths score by race\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")\n\n\n\n\n\n\n3.2.2 ) Reveal the 95% confidence interval of mean Maths score by race\nError bars sorted by the average maths scores.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean - 1.96*se, \n        ymax=mean + 1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\" 95% confidence interval of mean maths score by race \")\n\n\n\n\n\n\n3.2.3) Visualizing the uncertainty of point estimates with interactive error bars\n\nd <- highlight_key(my_sum) \n\np <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean - 2.58*se, \n        ymax=mean + 2.58*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  \n    geom_point(aes\n           (x=RACE, \n            y=mean,\n            text = paste(\"Race:\", RACE,\n                     \"<br>N:\", n,\n                     \"<br>Avg. Scores:\", round(mean, digits = 2),\n                     \"<br>99% CI:[\", round(mean - 2.58*se, digits = 2), \", \", round(mean + 2.58*se, digits = 2), \"]\")), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  \n  ggtitle(\" 99% confidence interval of mean maths score by race \")\n\ngg <- highlight(ggplotly(p,tooltip = \"text\"),        \n                \"plotly_selected\")  \n\ndt <- DT::datatable(d,\n                    colnames = c(\" \", \"No. of pupils\", \"Avg Scores\", \"Std Dev\", \"Std Error\")) |> \n  formatRound(columns = c(\"mean\", \"sd\", \"se\"), digits = 2)\n\ncrosstalk::bscols(gg,               \n                  dt, \n                  widths = 5)        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3) Visualizing Uncertainty using ggdist\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualizing distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualizes confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualizes probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n3.3.1 ) Using stat_pointinterval() of ggdist\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +   #<<\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n3.3.2 ) Visualization of 95% and 99% confidence interval with mean\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n  .point = mean,\n  .interval = c(qi(0.95),qi(0.99))) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n3.3.3 ) Visualizing the uncertainty of point estimates: ggdist methods\nUsing stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n3.4) Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\n3.4.1) Getting Started\n\nInstalling ungeviz package\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\nLaunch the application in R\n\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plots-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plots-with-r",
    "title": "Hands-on Exercise 4",
    "section": "4) Funnel Plots with R",
    "text": "4) Funnel Plots with R\nFunnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities.\n\n4.1) Getting Started\n\nUsing p_load() of pacman package to load the required libraries\n\n\nFive R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\nImporting data\n\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)\n\n\n\n4.2) FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customization are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot. xrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n4.2.1) FunnelPlotR methods: The basic plot\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. Plot is adjusted for overdispersion.\n\n4.2.1.1) Makeover 1\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #<<\n  xrange = c(0, 6500),  #<<\n  yrange = c(0, 0.05)   #<<\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. Plot is adjusted for overdispersion.\n\n\n4.2.1.2) Makeover 2\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. Plot is adjusted for overdispersion.\n\n\n\n\n4.3) FunnelPlotR methods: ggplot2 methods\nTo begin with, we derive cumulative death rate and standard error of cumulative death rate.\nData Preparation\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\nCalculate lower and upper limits for 95% and 99.9% CI\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\nPlotting a static funnel plot\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\nInteractive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse) \n\n\nImporting data\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualization-with-ggiraph",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualization-with-ggiraph",
    "title": "Hands-on Exercise 3",
    "section": "1) Interactive Data Visualization with ggiraph",
    "text": "1) Interactive Data Visualization with ggiraph\nStudent ID will appear when the mouse hovered to the specific data point.\n\nOutput:\n\np <-ggplot(data=exam_data, \n       aes(x = MATHS)) +\n    geom_dotplot_interactive(\n       aes(tooltip = ID),\n       stackgroups = TRUE, \n       binwidth = 1, \n       method = \"histodot\") +\n       scale_y_continuous(NULL, breaks = NULL)\n    \n    girafe(\n       ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618\n             )\n\n\n\n\n\n\n\n1.1) Displaying multiple information with tooltip\nStudent ID and Class will appear when the mouse hovered to the specific data point.\n\nOutput:\n\nexam_data$tooltip <- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n     geom_dotplot_interactive(\n       aes(tooltip = exam_data$tooltip), \n       stackgroups = TRUE,\n       binwidth = 1,\n       method = \"histodot\") +\n       scale_y_continuous(NULL, breaks = NULL)\n\n     girafe(\n       ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n           )\n\n\n\n\n\n\n\n\n1.2) Customizing tooltip style\nWhen the mouse hovered to the specific data point, the student ID will appear. We will customize the output to black and bold font with white background.\n\nOutput:\n\ntooltip_css <- \"background-color:white; #<<\nfont-style:bold; color:black;\" #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n     geom_dotplot_interactive(              \n       aes(tooltip = ID),                   \n       stackgroups = TRUE,                  \n       binwidth = 1,                        \n       method = \"histodot\") +               \n       scale_y_continuous(NULL,               \n                     breaks = NULL)\n    girafe(                                  \n      ggobj = p,                             \n      width_svg = 6,                         \n      height_svg = 6*0.618,\n      options = list(    #<<\n      opts_tooltip(    #<<\n      css = tooltip_css)) #<<\n          )                                        \n\n\n\n\n\n\n\n\n1.3) Displaying statistics with tooltip\nWhen the mouse hovered to the specific data point, statistics will appear. In the below output, confidence interval will be displayed at 90% CI.\n\nOutput:\n\ntooltip <- function(y, ymax, accuracy = .01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean Maths Scores:\", mean, \"+/-\", sem)\n}\n\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),) +\n            stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                  tooltip(y, ymax))),  \n            fun.data = \"mean_se\", \n                  geom = GeomInteractiveCol,  \n                  fill = \"light blue\"\n                  ) +\n           stat_summary(aes(y = MATHS),\n                 fun.data = mean_se,\n                 geom = \"errorbar\", width = 0.2, linewidth = 0.2\n                  )\n\n           girafe(ggobj = gg_point,\n               width_svg = 8,\n               height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n1.4) Hover effect with data_id aesthetic\nWhen the mouse hovered to the specific data point, data points that are associated with the data_id(CLASS) will be highlighted.\n\nOutput:\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n     geom_dotplot_interactive(           \n       aes(data_id = CLASS),             \n       stackgroups = TRUE,               \n       binwidth = 1,                        \n       method = \"histodot\") +               \n     scale_y_continuous(NULL, breaks = NULL)\n\n     girafe(                                  \n       ggobj = p,                             \n       width_svg = 6,                         \n       height_svg = 6*0.618                      \n        )                                        \n\n\n\n\n\n\n\n\n1.5) Customizing Hover effect\nSimilar to 1.2, we will customize the Hover Effect with the help of CSS.\n\nOutput:\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n     geom_dotplot_interactive(              \n       aes(data_id = CLASS),              \n       stackgroups = TRUE,                  \n       binwidth = 1,                        \n       method = \"histodot\") +               \n     scale_y_continuous(NULL, breaks = NULL)\n\n     girafe(                                  \n       ggobj = p,                             \n       width_svg = 6,                         \n       height_svg = 6*0.618,\n       options = list(                        \n       opts_hover(css = \"fill: #202020;\"),  \n       opts_hover_inv(css = \"opacity:0.2;\") \n           )                                        \n             )                                        \n\n\n\n\n\n\n\n\n1.6) Combining tooltip and Hover Effect\nIn the below output, we will combine both Interactive Data Visualization. The respective data points and the associated points will be reflected.\n\nOutput:\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n     geom_dotplot_interactive(              \n       aes(tooltip = CLASS, \n       data_id = CLASS),              \n       stackgroups = TRUE,                  \n       binwidth = 1,                        \n       method = \"histodot\") +               \n     scale_y_continuous(NULL, breaks = NULL)\n     \n     girafe(                                  \n       ggobj = p,                             \n       width_svg = 6,                         \n       height_svg = 6*0.618,\n      options = list(                        \n      opts_hover(css = \"fill: #202020;\"),  \n      opts_hover_inv(css = \"opacity:0.2;\") \n         )                                        \n           )                                        \n\n\n\n\n\n\n\n\n1.7) Click effect with onclick\nIn the below output, a new window will open upon a click (hotlink interactivity)\nNote: Click actions must be a string column\n\nOutput:\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n     geom_dotplot_interactive(              \n       aes(onclick = onclick),              \n       stackgroups = TRUE,                  \n       binwidth = 1,                        \n       method = \"histodot\") +               \n     scale_y_continuous(NULL, breaks = NULL)\n\n     girafe(                                  \n       ggobj = p,                             \n       width_svg = 6,                         \n       height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\n\n1.8) Coordinated multiple views\nIn the below output, the graph will be interactive. Hovering on one data point will reflect the corresponding data point. We will be using :\n\npatchwork function [use inside girafe function]\nggiraph [use to create multiple views]\n\nNote: data_id aesthetic is critical, tooltip aesthetic is optional\n\nOutput:\n\np1 <- ggplot(data=exam_data, \n        aes(x = MATHS)) +\n     geom_dotplot_interactive(              \n       aes(data_id = ID),              \n       stackgroups = TRUE,                  \n       binwidth = 1,                        \n       method = \"histodot\") +  \n     coord_cartesian(xlim=c(0,100)) + \n     scale_y_continuous(NULL, breaks = NULL)\n\np2 <- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n     geom_dotplot_interactive(              \n       aes(data_id = ID),              \n       stackgroups = TRUE,                  \n       binwidth = 1,                        \n       method = \"histodot\") + \n     coord_cartesian(xlim=c(0,100)) + \n     scale_y_continuous(NULL, breaks = NULL)\n\n     girafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n            )\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualization-with-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualization-with-plotly",
    "title": "Hands-on Exercise 3",
    "section": "2) Interactive Data Visualization with plotly",
    "text": "2) Interactive Data Visualization with plotly\nThere are two ways to create interactive graph through plotly:\n\nplot_ly()\nggploty()\n\n\n2.1) Create interactive scatter plot with plot_ly() method\nIn the below output, the interactive graph is created through plot_ ly().\n\nOutput:\n\nplot_ly(data = exam_data, \n             x = ~MATHS, y = ~ENGLISH)\n\n\n\n\n\n\n\n\n2.2) Create interactive scatter plot with plot_ly() method\nIn the below output, the interactive graph is enhanced with the addition of RACE as a visual variable.\n\nOutput:\n\nplot_ly(data = exam_data, \n             x = ~MATHS, y = ~ENGLISH, color = ~RACE)\n\n\n\n\n\n\n\n\n2.3) Create interactive scatter plot with ggplotly() method\nIn the below output, the interactive graph is created through ggplotly().\n\nOutput:\nNote: only 1 additional line required (Line 7)\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n     geom_point(size=1) +\n    coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n2.4) Coordinated multiple views with plotly\nThe coordinated linked graphs will be achieved in three steps:\n\nUse highlight_key() of plotly as a shared data\nCreate two scatter plots through ggplot2 functions\nSubplot() of plotly package used to place them side by side\n\n\nOutput:\n\nd <- highlight_key(exam_data)\n\np1 <- ggplot(data=d, \n         aes(x = MATHS, y = ENGLISH)) +\n      geom_point(size=1) +\n      coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\np2 <- ggplot(data=d, \n         aes(x = MATHS, y = SCIENCE)) +\n      geom_point(size=1) +\n      coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nNote to self: patchwork is not interactive in comparion but includes labelling"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualization-with-crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualization-with-crosstalk-methods",
    "title": "Hands-on Exercise 3",
    "section": "3) Interactive Data Visualization with crosstalk methods",
    "text": "3) Interactive Data Visualization with crosstalk methods\nIt is an add-on to htmlwidgets package with cross-widget interactions.\n\n3.1) Interactive Data Table: DT package\nIn the below output, the interactive data table is created through DT package.\n\nOutput:\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\n3.2) Linked brushing crosstalk method\nIn the below output, the interactive data table is created through DT package.\n\nOutput:\n\nd <- highlight_key(exam_data) \n\np <- ggplot(d, \n       aes(ENGLISH, MATHS)) + \n     geom_point(size=1) +\n     coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualization-with-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualization-with-gganimate-methods",
    "title": "Hands-on Exercise 3",
    "section": "4) Animated Data Visualization with gganimate methods",
    "text": "4) Animated Data Visualization with gganimate methods\ngganimate is an extension of ggplot2 which includes animation and includes the following:\n\ntransition_() defines how the data should be spread out and how it relates to itself across time.\nview_() defines how the positional scales should change along the animation.\nshadow_() defines how data from other points in time should be presented in the given point in time.\nenter_()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nSource\nPrior to building the graph, we would need to:\n\nUsing p_load() of pacman package to load the required libraries\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\nImporting data\n\n\ncol <- c(\"Country\", \"Continent\")\nglobalPop <- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %>%\n  mutate_each_(funs(factor(.)), col) %>%\n  mutate(Year = as.integer(Year))\n\n\n\n4.1) Building a static population bubble plot\nIn the below output, basic ggplot2 functions are used to create a static bubble plot.\n\nOutput:\n\nggplot(globalPop, \n       aes(x = Old, y = Young, \n       size = Population, \n       colour = Country)) +\n  geom_point(alpha = 0.7, \n       show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n4.2) Building the animation bubble plot\nSimilar to 4.1, the below output will be animated.\n\nOutput:\n\nggplot(globalPop, \n       aes(x = Old, y = Young, \n       size = Population, \n       colour = Country)) +\n  geom_point(alpha = 0.7, \n       show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualization-with-plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualization-with-plotly-methods",
    "title": "Hands-on Exercise 3",
    "section": "5) Animated Data Visualization with plotly methods",
    "text": "5) Animated Data Visualization with plotly methods\nSimilar to section 4, both ggplotly and plotly support animated data visualization.\n\n5.1) Building an animated bubble plot plotly\nIn this sub-section, we will create an animated bubble plot..\n\nOutput:\n\nbp <- globalPop %>%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent, \n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          )\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes,tidyverse) \n\n\nImporting data\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#english-scores-vs-maths-scores-for-primary-3",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#english-scores-vs-maths-scores-for-primary-3",
    "title": "Hands-on Exercise 2",
    "section": "1) English scores vs Maths scores for Primary 3",
    "text": "1) English scores vs Maths scores for Primary 3\n\nOutput:\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n       geom_point() +\n       geom_smooth(method=lm, size=0.5) +  \n       geom_label_repel(aes(label = ID), fontface = \"bold\") +\n       coord_cartesian(xlim=c(0,100), ylim=c(0,100)) +\n       ggtitle(\"English scores versus Maths scores for Primary 3\") +\n       theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#distribution-of-maths-scores",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#distribution-of-maths-scores",
    "title": "Hands-on Exercise 2",
    "section": "2) Distribution of Maths scores",
    "text": "2) Distribution of Maths scores\n\nOutput:\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n       geom_histogram(bins= 30, color= \"grey30\", fill = \"grey95\") +\n       coord_cartesian(xlim=c(0,100)) +\n       theme_grey() + \n       ggtitle(\"Distribution of Maths scores\") +\n       theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n2.1) ggtheme package\n\nThemes here\n\n\nOutput:\n\nggplot(data = exam_data, \n       aes(x=MATHS)) + \n       geom_histogram(bins=30, color= \"grey30\", fill = \"grey95\") +\n       coord_cartesian(xlim=c(0,100)) +\n      theme_economist() +\n       ggtitle(\"Distribution of Maths scores\") +\n       theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n2.2) hrbthems package\n\nThemes here\n\n\nOutput:\n\nggplot(data = exam_data, \n       aes(x=MATHS)) + \n       geom_histogram(bins=20, boundary = 100,  \n       color= \"grey30\", fill = \"grey95\") +\n       coord_cartesian(xlim=c(0,100)) +\n       theme_ipsum() +\n       ggtitle(\"Distribution of Maths scores\") +\n       theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n2.2.1) hrbthems package: theme revision\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and,\ngrid argument is used to remove the x-axis grid lines.\n\n\nOutput:\n\nggplot(data = exam_data, \n       aes(x=MATHS)) + \n       geom_histogram(bins=20, boundary = 100,  \n       color= \"grey30\", fill = \"grey95\") +\n       coord_cartesian(xlim=c(0,100)) +\n       theme_ipsum(grid = \"y\",axis_title_size = 18, base_size =15) +\n       ggtitle(\"Distribution of Maths scores\") +\n       theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-multiple-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-multiple-graphs",
    "title": "Hands-on Exercise 2",
    "section": "3) Creating multiple graphs",
    "text": "3) Creating multiple graphs\nCreate composite plot by combining multiple graphs. Firstly, to create three statistical graphics.\n\n3.1) Distribution of Maths Scores\n\nOutput:\n\np1 <- ggplot(data = exam_data, \n       aes(x=MATHS)) + \n       geom_histogram(bins=20, boundary = 100,  \n       color= \"grey30\", fill = \"grey95\") +\n       coord_cartesian(xlim=c(0,100)) +\n       ggtitle(\"Distribution of \\nMaths scores\") +\n       theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n3.2) Distribution of English Scores\n\nOutput:\n\np2 <- ggplot(data = exam_data, \n       aes(x=ENGLISH)) + \n       geom_histogram(bins=20, boundary = 100,  \n       color= \"grey30\", fill = \"grey95\") +\n       coord_cartesian(xlim=c(0,100)) +\n       ggtitle(\"Distribution of \\nEnglish scores\") +\n       theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n3.3) English scores vs Maths scores for Primary 3\n\nOutput :\n\np3 <- ggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n       geom_point() +\n       geom_smooth(method=lm, size=0.5) +  \n       coord_cartesian(xlim=c(0,100), ylim=c(0,100)) +\n       ggtitle(\"English scores vs Maths \\nscores for Primary 3\") +\n       theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-multiple-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-multiple-graphs",
    "title": "Hands-on Exercise 2",
    "section": "4) Plotting multiple graphs",
    "text": "4) Plotting multiple graphs\nPoint to note:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\n\nTwo-Row Layout using the Division Sign /\n\nSource\n\n\n4.1) Combine 3.1 and 3.2\nIn this output, we will combine Distribution of Maths Scores and Distribution of English Scores.\n\nOutput :\n\np1 + p2\n\n\n\n\n\n\n\n4.2) Combine 3.1, 3.2, and 3.3\nPoint to note:\n\n“|” operator to stack two ggplot2 graphs,\n“/” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nSource\nIn this output, we will combine Distribution of Maths Scores, Distribution of English Scores, and English scores vs Maths scores for Primary 3 by stacking 3.1 and 3.2 on the left and 3.3 on the right.\n\n\nOutput :\n\np1 / p2 | p3\n\n\n\n\n\n\n\n4.3) Insert 3.2 into 3.3\nIn this output, we will insert Distribution of English Scores on top of English scores vs Maths scores for Primary 3.\n\nOutput :\n\np3 + inset_element(p2, left = 0.02, bottom = 0.6, right = 0.4, top = 1)\n\n\n\n\n\n\n\n4.4) Add patchwork and ggtheme to 4.2\nIn this output, we will add patchwork and ggtheme.\n\nOutput :\n\npatchwork <- p1 / p2 | p3\npatchwork & theme_economist(base_size = 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\nImporting data\n\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n2.1 Reviewing imported data\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reformat-date-using-lubridate",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reformat-date-using-lubridate",
    "title": "Hands-on Exercise 5",
    "section": "1.1 Reformat Date using lubridate",
    "text": "1.1 Reformat Date using lubridate\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\nGAStech_edges\n\n# A tibble: 9,063 × 10\n   source target SentDate SentTime Subject   MainSubject sourceLabel targetLabel\n    <dbl>  <dbl> <chr>    <time>   <chr>     <chr>       <chr>       <chr>      \n 1     43     41 6/1/2014 08:39    GT-Seism… Work relat… Sven.Flecha Isak.Baza  \n 2     43     40 6/1/2014 08:39    GT-Seism… Work relat… Sven.Flecha Lucas.Alca…\n 3     44     51 6/1/2014 08:58    Inspecti… Work relat… Kanon.Herr… Felix.Resu…\n 4     44     52 6/1/2014 08:58    Inspecti… Work relat… Kanon.Herr… Hideki.Coc…\n 5     44     53 6/1/2014 08:58    Inspecti… Work relat… Kanon.Herr… Inga.Ferro \n 6     44     45 6/1/2014 08:58    Inspecti… Work relat… Kanon.Herr… Varja.Lagos\n 7     44     44 6/1/2014 08:58    Inspecti… Work relat… Kanon.Herr… Kanon.Herr…\n 8     44     46 6/1/2014 08:58    Inspecti… Work relat… Kanon.Herr… Stenig.Fus…\n 9     44     48 6/1/2014 08:58    Inspecti… Work relat… Kanon.Herr… Hennie.Osv…\n10     44     49 6/1/2014 08:58    Inspecti… Work relat… Kanon.Herr… Isia.Vann  \n# ℹ 9,053 more rows\n# ℹ 2 more variables: SendDate <date>, Weekday <ord>\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\nSource"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#wrangling-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#wrangling-attributes",
    "title": "Hands-on Exercise 5",
    "section": "1.2 Wrangling Attributes",
    "text": "1.2 Wrangling Attributes\nGAStech_edges data.frame consists of individual e-mail flow records which is not very useful. We will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\nGAStech_edges_aggregated\n\n# A tibble: 1,372 × 4\n   source target Weekday   Weight\n    <dbl>  <dbl> <ord>      <int>\n 1      1      2 Sunday         5\n 2      1      2 Monday         2\n 3      1      2 Tuesday        3\n 4      1      2 Wednesday      4\n 5      1      2 Friday         6\n 6      1      3 Sunday         5\n 7      1      3 Monday         2\n 8      1      3 Tuesday        3\n 9      1      3 Wednesday      4\n10      1      3 Friday         6\n# ℹ 1,362 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#using-tbl_graph-to-build-tidygraph-data-model",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#using-tbl_graph-to-build-tidygraph-data-model",
    "title": "Hands-on Exercise 5",
    "section": "2.1 Using tbl_graph() to build tidygraph data model",
    "text": "2.1 Using tbl_graph() to build tidygraph data model\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#changing-the-active-object",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#changing-the-active-object",
    "title": "Hands-on Exercise 5",
    "section": "2.2 Changing the active object",
    "text": "2.2 Changing the active object\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 5",
    "section": "2.3 Plotting Static Network Graphs with ggraph package",
    "text": "2.3 Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph's network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n2.3.1. Changing the default network graph theme\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n2.3.2. Plot network graph using Fruchterman and Reingold layout\n\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n2.3.3. Modifying network nodes\nModifying the nodes to the respective departments\n\ng <- ggraph(GAStech_graph, \n            layout = \"with_gem\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nRefer to 27.5.4 for layout here\n\n\n2.3.4. Modifying edges\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "title": "Hands-on Exercise 5",
    "section": "3. Creating facet graphs",
    "text": "3. Creating facet graphs\nAnother very useful feature of ggraph is faceting. This technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. There are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n3.1 Working with facet_edges()\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n3.2 Working with facet_edges()\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  #to change legend to the bottom\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n3.3 A framed facet graph\n\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\nfacet_nodes() is used for the following example.\n\n\n3.4. Working with facet_nodes()\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "title": "Hands-on Exercise 5",
    "section": "4. Network Metrics Analysis",
    "text": "4. Network Metrics Analysis\n\n4.1 Computing centrality indices\nThere are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector.\n\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n4.2 Visualizing network metrics\n\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n4.3 Visualizing Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal).\ngroup_edge_betweenness() is used.\n\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 5",
    "section": "5. Interactive Network Graph with visNetwork",
    "text": "5. Interactive Network Graph with visNetwork\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an \"id\" column, and the edge list must have \"from\" and \"to\" columns.\nThe function also plots the labels for the nodes, using the names of the actors from the \"label\" column in the node list.\n\n\n5.1 Data Preparation\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\n5.2 Plotting the interactive network graph\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\n5.3 Working with visual attributes - Nodes\nvisNetwork() looks for a field called \"group\" in the nodes object and colour the nodes according to the values of the group field.\nvisNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n5.4 Working with visual attributes - Edges\nvisEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n5.5. Incorporate Interactivity\nvisOptions() is used to incorporate interactivity features in the data visualisation.\n- The argument highlightNearest highlights nearest when clicking a node.\n- The argument nodesIdSelection adds an id node selection creating an HTML select element.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, \n               data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\nImporting Data\n\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\n\nData Preparation\n\nStep 1: Deriving weekday and hour of day fields\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nExtract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\nStep 3: Plotting the heatmaps\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\narrivals_by_air.xlsx will be used for this exercise.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nStep 1: Derive month and year field\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\nStep 2: Select the target country\n\nVietnam <- air |> \n  select(Vietnam,\n         month,\n         year) |> \n  filter(year >= 2010)\n\nStep 3: Compute year average by months\n\nhline.data <- Vietnam |> \n  group_by(month) |> \n  summarise(avgvalue = mean(Vietnam))\n\n\n\n\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")\n\n\n\n\n\n\n\n\n\n\nrice.csv will be used for this exercise.\n\nrice <- read_csv(\"data/rice.csv\")\n\n\n\n\n\nrice %>% \n  mutate(Year = factor(Year)) %>%\n  filter(Year %in% c(1961, 1980)) %>%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Oh Jia Wen\")\n\n\n\n\n\n\n\n\nDo refer to In-class Exercise 07"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands_on_Ex06_PartTwo.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands_on_Ex06_PartTwo.html",
    "title": "Hands-on Exercise 6 Part Two",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\npacman::p_load(corrplot, ggstatsplot, tidyverse, GGally, \n               parallelPlot, treemap, treemapify)\n\n\nImporting Data\n\n\nwine <- read_csv(\"data/wine_quality.csv\")\nrealis2018 <- read_csv(\"data/realis2018.csv\")\n\n\n\nCreate a scatterplot matrix by using the pairs function of R Graphics.\n\n\n\npairs(wine[,1:11])\n\n\n\n\nAnother example. This time, it uses column 2 to 12 to the build the scatter plot matrix.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\nSince correlation matrix is symmetric, we would like to see the lower half or upper half. Thus, we would need to choose between upper.panel = NULL or lower.panel = NULL .\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\npanel.cor function will be used to show the correlation coefficient of each pair of variables instead of a scatter plot.\n\npanel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr <- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr <- abs(cor(x, y, use=\"complete.obs\"))\ntxt <- format(c(r, 0.123456789), digits=digits)[1]\ntxt <- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)\n\n\n\n\n\n\n\n\nWe will be using ggcorrmat() of ggstatsplot package.\n\n#|fig.height: 12\n#|fig.width: 6\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n)\n\n\n\n\n\n#help to control specific component of the plot such \nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\n\nggstatsplot package supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\n#|fig.height: 12\n#|fig.width: 6\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,        #to build facet plot\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  \n  #provides list of additional arguments\n  plotgrid.args = list(ncol = 2),       \n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  \n  #calling plot annotations arguments of patchwork\n  annotation.args = list(               \n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\nWe will be using corrplot() of the corrplot package. Check out -> An Introduction to corrplot Package for basic understanding of corrplot package.\n\nwine.cor <- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\nThere are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle.\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\",  #default is circle \n         type=\"lower\",        #default is full\n         diag = FALSE,        #turn off diagonal celss\n         tl.col = \"black\")    #change axis text label color to black \n\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,  #input the calculated conf.level\n         sig.level = .05)\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",        #instead of diag, change to order = \"hclust\"\n               order=\"AOE\",   #order_type.  then hcluster.method = \"ward.D\"\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\nUsing p_load() of pacman package to load the required libraries\n\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\nImporting data\n\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\nPreparing the data\n\n\nrow.names(wh) <- wh$Country\n\n\nTransform to Matrix\n\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\n\n\nWe will be using heatmap() of Base Stats.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\nTo plot cluster heatmap,\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\n\n\n\nWe will be using heatmaply in this section.\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nheatmaply uses the seriation package to find an optimal ordering of rows and columns.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n\n\n\n\n\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\n\nRefer to url for more explanation.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\nparallelPlotis used in this section.\n\nwh_i <- wh |> \n  select(\"Happiness score\", c(7:12))\n\n\nhisto <- rep(TRUE, ncol(wh_i))\n\nparallelPlot(wh_i,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE,\n             histoVisibility = histo)\n\n\n\n\n\n\n\n\n\nGrouped summaries with pipe\n\nrealis2018_summarised <- realis2018 %>% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %>%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\nThereafter, we filter for condominium in property type and resale type of flat.\n\nrealis2018_selected <- realis2018_summarised %>%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\nAs the file have been installed previous in Take Home Exercise 2, we will not install the github again.\n\n#library(devtools)\n#install_github(\"timelyportfolio/d3treeR\")\n\nlibrary(d3treeR) #package have been installed in Take Home Exercise 2 \n\n\n\n\ntm <- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6 Part One",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\n\npacman::p_load('plotly', 'tidyverse',\"ggtern\", 'corrplot', 'ggstatsplot', 'corrgram', 'ellipse')\n\n\nImporting data\n\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\nPreparing the data\n\n\n#Deriving the young, economy active and old measures\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  pivot_wider(names_from = AG, values_from = Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\n\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n# reusable function for creating annotation object\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "City of Engagement is a small city located at Country of Nowhere, with a total population of 50,000, serving as an agriculture region. The local council of the city is in the midst of preparing the Local Plan 2023.\n\n\nIn this take-home exercise, patterns containing demographics and financial characteristics of residents in City of Engagement will be unveiled using appropriate static and interactive statistical graphics methods."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#metadata",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#metadata",
    "title": "Take Home Exercise 1",
    "section": "2.1 Metadata",
    "text": "2.1 Metadata\n\n\n\n\n\n\n\n\nFile\nVariables Name\nDescription\n\n\n\n\nparticipants.csv\nFinancialJourval.csv\nparticipantId\nUnique identification to represent the Participants\n\n\nparticipants.csv\nhouseholdSize\nRepresents the number of people in the household\n\n\nparticipants.csv\nhaveKids\nBinary value (True/False) indicating if participant have a kid(s)\n\n\nparticipants.csv\nage\nRepresents age of the participant\n\n\nparticipants.csv\neducationLevel\nRepresents the highest education attained by participant\n\n\nFinancialJourval.csv\ninterestGroup\nRepresents the group associated with the participant\n\n\nFinancialJourval.csv\njoviality\nRepresents the level of happiness by participant at the start of the survey\n\n\nFinancialJourval.csv\ntimestamp\nRepresents the date and time the entry was inputted\n\n\nFinancialJourval.csv\ncategory\nRepresents the type of income/expenses incurred at a given timestamp\n\n\nFinancialJourval.csv\namount\nRepresents the amount received ( + income), amount paid ( - expenses )"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#install-r-packages",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#install-r-packages",
    "title": "Take Home Exercise 1",
    "section": "3.1 Install R-packages",
    "text": "3.1 Install R-packages\nUsing p_load() of pacman package to load and install the following libraries:\n\nggiraph : For creating interactive ‘ggplot’ graphics\nplotly : For creating interactive statistical graphs\npatchwork : For combining multiple ggplot2 graphs into one figure\ntidyverse : A collection of R packages use in everyday data analyses. It is able to support data science, data wrangling, and analysis.\nknitr: For dynamic report generation\nggstatsplot: For creating graphics with details from statistical tests included and its plot\npaletteer: Collection of color palettes\nwesanderson: Wes Anderson’s theme Palette Generator\nscales: For customizing the appearance of axis and legend labels\npng: For reading, writing, and displaying bitmap imaged in PNG format\nnortest: For normality test\nwebshot2: For taking screenshot of web pages\nrstatix: For performing statistical tests and correlation analyses\ngt : For constructing of table\nstats : For statistical calculations\ngridExtra: For arranging multiple grid-based plot on a page, and draw tables\nggpubr: For creating and customizing ‘ggplot2’ based plots\nggdist: For visualization of distributions and uncertainty\n\n\npacman::p_load(ggiraph, plotly, patchwork, tidyverse,\n               knitr,ggstatsplot,paletteer,wesanderson,\n               scales, ggpubr, rstatix,gt,webshot2,\n               png,nortest, stats, gridExtra,ggdist)\n\noptions(scipen = 999)\n\n\n\n\n\n\n\nTip\n\n\n\noptions(scipen = 999) : removes scientific notation in our exercise."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#import-data",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#import-data",
    "title": "Take Home Exercise 1",
    "section": "3.2 Import Data",
    "text": "3.2 Import Data\n\n3.2.1 Import participants dataset\n\nparticipants <- read_csv(\"data/Participants.csv\")\n\n\n\n3.2.2 Load participants\n\nData TableCode\n\n\n\n\n# A tibble: 6 × 7\n  participantId householdSize haveKids   age educationLevel      interestGroup\n          <dbl>         <dbl> <lgl>    <dbl> <chr>               <chr>        \n1             0             3 TRUE        36 HighSchoolOrCollege H            \n2             1             3 TRUE        25 HighSchoolOrCollege B            \n3             2             3 TRUE        35 HighSchoolOrCollege A            \n4             3             3 TRUE        21 HighSchoolOrCollege I            \n5             4             3 TRUE        43 Bachelors           H            \n6             5             3 TRUE        32 HighSchoolOrCollege D            \n# ℹ 1 more variable: joviality <dbl>\n\n\n\n\n\nhead(participants)\n\n\n\n\n\n\n3.2.3 Import Financial Journal dataset\n\nfinancial_journal <- read_csv(\"data/FinancialJournal.csv\")\n\n\n\n3.2.4 Load Financial Journal\n\nData TableCode\n\n\n\n\n# A tibble: 6 × 4\n  participantId timestamp           category  amount\n          <dbl> <dttm>              <chr>      <dbl>\n1             0 2022-03-01 00:00:00 Wage      2473. \n2             0 2022-03-01 00:00:00 Shelter   -555. \n3             0 2022-03-01 00:00:00 Education  -38.0\n4             1 2022-03-01 00:00:00 Wage      2047. \n5             1 2022-03-01 00:00:00 Shelter   -555. \n6             1 2022-03-01 00:00:00 Education  -38.0\n\n\n\n\n\nhead(financial_journal)"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "title": "Take Home Exercise 1",
    "section": "3.3 Data Wrangling",
    "text": "3.3 Data Wrangling\nAs seen from the two data tables above, there are some issues that could be rectify. Henceforth, the following adjustments are made:\n3.3.1 participants.csv :\n\nparticipantId is a <dbl> variable. (Rectify by reformatting it to <chr>)\nhouseholdSize is a <dbl> variable. (Revised to <ord> for the order of categories)\nage is a continuous variable which makes it harder to visualize the demographics (Create a new column with 5-class variables after determining the youngest and oldest demographics.)\n\n\n\nShow the code\n#check min and max age of residents in COE. \nmin(participants$age)\n\n\n[1] 18\n\n\nShow the code\nmax(participants$age)\n\n\n[1] 60\n\n\n\neducationLevel is a <chr> variable. (Revised to <ord> for the order of categories)\njoviality has nine decimal places. (Rectify by rounding it to 2.d.p and create new 5-class variables for future analysis)\n\n\n\nShow the code\n#create new dataset \nparticipants_new <- participants %>%\n    mutate(\n          participantId = as.character(participantId),\n          #binned joviality to 5-class variables \n          joviality_bins = cut(joviality, breaks = c(0.0,0.2,0.4,0.6,0.8,1.0))\n          )\n\n#reformat householdSize to Ordinal \n    participants_new$householdSize <- factor(participants$householdSize,\n                                      levels = c(\"1\", \"2\", \"3\"), \n                                      ordered = TRUE) \n#reformat age group \nparticipants_new$age_group <- factor(ifelse(participants$age < 20, \"Under 20\",\n                ifelse(participants$age < 30, \"20-29\",\n                    ifelse(participants$age < 40, \"30-39\",\n                      ifelse(participants$age < 50, \"40-49\", \"Above 50\")))),\n                levels = c(\"Under 20\", \"20-29\", \"30-39\", \"40-49\", \"Above 50\"),\n                ordered= TRUE)\n\n#reformat education level to Ordinal \nparticipants_new$educationLevel <- factor(participants$educationLevel, \n                                      levels = c(\"Low\", \"HighSchoolOrCollege\", \n                                                 \"Bachelors\", \"Graduate\"\n                                                 ), \n                                      ordered = TRUE)  \n\n#round up joviality to 2 decimal places \nparticipants_new$joviality <- round(participants$joviality, 2) \n\n#output data frame\nparticipants_new\n\n\n# A tibble: 1,011 × 9\n   participantId householdSize haveKids   age educationLevel      interestGroup\n   <chr>         <ord>         <lgl>    <dbl> <ord>               <chr>        \n 1 0             3             TRUE        36 HighSchoolOrCollege H            \n 2 1             3             TRUE        25 HighSchoolOrCollege B            \n 3 2             3             TRUE        35 HighSchoolOrCollege A            \n 4 3             3             TRUE        21 HighSchoolOrCollege I            \n 5 4             3             TRUE        43 Bachelors           H            \n 6 5             3             TRUE        32 HighSchoolOrCollege D            \n 7 6             3             TRUE        26 HighSchoolOrCollege I            \n 8 7             3             TRUE        27 Bachelors           A            \n 9 8             3             TRUE        20 Bachelors           G            \n10 9             3             TRUE        35 Bachelors           D            \n# ℹ 1,001 more rows\n# ℹ 3 more variables: joviality <dbl>, joviality_bins <fct>, age_group <ord>\n\n\n3.3.2 FinancialJourval.csv :\n\nSimilar issue as point 1 above.\nTimestamp is a <POSIX> variable. (Rectify by reformatting it to <chr> in year-mth format)\nAs per the code below, there are duplicate entries in the financial journal. (Rectify by using the distinct() function from [dplyr package] in tidyverse)\n\n\n\nShow the code\n#check for duplicates \ndup <- (nrow(financial_journal) - nrow(unique(financial_journal)))\n#reformat output \ndup_reformat <- format(dup, big.mark=\",\")\n#print output\ndup_reformat\n\n\n[1] \"1,113\"\n\n\n\n“Category” is not very useful. (Rectify by using pivot_wider() function from [tidyr package] to transpose)\n\n\n\nShow the code\n    #remove duplicate rows for all columns\n    financial_journal_lessdup <- financial_journal %>% \n      distinct()\n\n    #create new dataset \n    grouped_data <- financial_journal_lessdup %>%\n      \n    #recode participantId from dbl to chr, format timestamp to year_mth and round amount \n        mutate(participantId = as.character(participantId),\n             year_mth = format(as.Date(financial_journal_lessdup$timestamp), \"%Y-%m\"),\n             amount = abs(round(amount,2)),\n             .before = 3) %>%\n      \n    #group the columns in the following order and sum the amount to total_amount\n      group_by( participantId, year_mth,category) %>%\n      summarize(total_amount = sum(amount)) \n\n    # pivot the data frame to have categories as columns\n    pivoted_fj <- grouped_data %>%\n      pivot_wider(names_from = \"category\", \n                  values_from = \"total_amount\", values_fill = 0)\n\n    # create new column from list of categories\n    pivoted_fj$Shelter_new <- pivoted_fj$Shelter + pivoted_fj$RentAdjustment\n    pivoted_fj$Expenses <- pivoted_fj$Education + pivoted_fj$Food +  \n    pivoted_fj$Recreation + pivoted_fj$Shelter + pivoted_fj$RentAdjustment\n    pivoted_fj$Income <- pivoted_fj$Wage\n    pivoted_fj$Cashflow <- pivoted_fj$Income - pivoted_fj$Expenses\n\n    # output the pivoted data frame\n    pivoted_fj %>%\n      select(c(1:5,7,9:12))\n\n\n# A tibble: 10,691 × 10\n# Groups:   participantId, year_mth [10,691]\n   participantId year_mth Education  Food Recreation   Wage Shelter_new Expenses\n   <chr>         <chr>        <dbl> <dbl>      <dbl>  <dbl>       <dbl>    <dbl>\n 1 0             2022-03       38.0  268.      349.  11932.        555.    1210.\n 2 0             2022-04       38.0  266.      219.   8637.        555.    1078.\n 3 0             2022-05       38.0  265.      383.   9048.        555.    1241.\n 4 0             2022-06       38.0  257.      466.   9048.        555.    1316.\n 5 0             2022-07       38.0  270.     1069.   8637.        555.    1933.\n 6 0             2022-08       38.0  262.      314.   9459.        555.    1169.\n 7 0             2022-09       38.0  256.      295.   9048.        555.    1144.\n 8 0             2022-10       38.0  267.       25.0  8637.        555.     885.\n 9 0             2022-11       38.0  261       377.   9048.        555.    1231.\n10 0             2022-12       38.0  266.      357.   9048.        555.    1216.\n# ℹ 10,681 more rows\n# ℹ 2 more variables: Income <dbl>, Cashflow <dbl>\n\n\n\nType of Income/Expenses are all labelled in a column. (Create new columns)\n\n\n\n\n\n\n\n\nData Table\nVariables Name\nDescription\n\n\n\n\nresident_profile_rev\nIncome\nCategory :Wage\n\n\nresident_profile_rev\nExpenses\nCategory: Education + Recreation + Food + Shelter_new (Shelter + RentAdjustment)\n\n\nresident_profile_rev\nCashflow\nNEW : Income - Expenses\n\n\n\nMultiple zero values for RentAdjustment. As seen from the data frame above and the code chunk below, there are only 72 rows. Thus, it will be combined with Shelter.\n\n\ncolSums(pivoted_fj[-1] !=0)\n\n      year_mth      Education           Food     Recreation        Shelter \n         10691           3018          10691           9492          10560 \n          Wage RentAdjustment    Shelter_new       Expenses         Income \n         10691             72          10560          10691          10691 \n      Cashflow \n         10691"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#merging-of-data-frame",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#merging-of-data-frame",
    "title": "Take Home Exercise 1",
    "section": "3.4 Merging of Data frame",
    "text": "3.4 Merging of Data frame\nFull_join will be used to create a new table by joining the cleaned participants dataset and pivoted financial journal dataset. It will be match by participant’s ID. Likewise, the sequence in the dataset will be relocated to highlight several columns.\n\n\nShow the code\n#join both data sets \nresident_profile <- full_join(participants_new, pivoted_fj, \n                       by = c(\"participantId\" = \"participantId\")) %>%\n#relocate columns to the front (by importance)\n                    relocate(year_mth, .after =participantId) %>%\n                    relocate(Cashflow, .after = year_mth) %>%\n                    relocate(age_group, .after = Cashflow) %>%\n                    relocate(educationLevel, .after = age_group) %>%\n                    relocate(Income, .after = haveKids) %>%\n                    relocate(Expenses , .after = Income) \nresident_profile %>%\n    select(c(1:18))\n\n\n# A tibble: 10,691 × 18\n   participantId year_mth Cashflow age_group educationLevel      householdSize\n   <chr>         <chr>       <dbl> <ord>     <ord>               <ord>        \n 1 0             2022-03    10722. 30-39     HighSchoolOrCollege 3            \n 2 0             2022-04     7559. 30-39     HighSchoolOrCollege 3            \n 3 0             2022-05     7808. 30-39     HighSchoolOrCollege 3            \n 4 0             2022-06     7733. 30-39     HighSchoolOrCollege 3            \n 5 0             2022-07     6704. 30-39     HighSchoolOrCollege 3            \n 6 0             2022-08     8291. 30-39     HighSchoolOrCollege 3            \n 7 0             2022-09     7904. 30-39     HighSchoolOrCollege 3            \n 8 0             2022-10     7752. 30-39     HighSchoolOrCollege 3            \n 9 0             2022-11     7817. 30-39     HighSchoolOrCollege 3            \n10 0             2022-12     7832. 30-39     HighSchoolOrCollege 3            \n# ℹ 10,681 more rows\n# ℹ 12 more variables: haveKids <lgl>, Income <dbl>, Expenses <dbl>, age <dbl>,\n#   interestGroup <chr>, joviality <dbl>, joviality_bins <fct>,\n#   Education <dbl>, Food <dbl>, Recreation <dbl>, Shelter <dbl>, Wage <dbl>\n\n\n\n3.4.1 Entries Check\nTo ensure data accuracy, the code chunk below checks the completeness of the data. Given that the data has a time period of one year, the code examines if the participants have entries for the entire time period.\n\n\nShow the code\n#check if participants_id have entries for the entire year \nparticipant_counts <- resident_profile %>%\n  group_by(participantId) %>%\n  summarise(num_months = n_distinct(year_mth)) %>%\n  ungroup()\n\nfiltered_count <- participant_counts %>%\n  filter(num_months != 12) %>%\n  nrow()\n\nfiltered_count \n\n\n[1] 131\n\n\nIt has been observed that there are 131 participants who do not have entries for the entire time period. To avoid inaccuracy, these group of participants will be excluded from the analysis.\n\n\n3.4.2 Missing Values Check\nThrough the code chunk below, we confirmed that there are no missing values in resident_profile dataset.\n\n#Check for missing values\nany(is.na(resident_profile))\n\n[1] FALSE\n\n\n\n\n3.4.3 Revised Resident’s Profile Dataset\nGiven that we have removed duplicates in section 3.3.2, removed entries in section 3.4.1 and observed no missing values in section 3.4.2, the resident’s profile data set have been revised. We will be using the knitr: kable() function to display the final dataset.\n\n\nShow the code\n#create a revised dataframe to exclude id that do not have entries for the time period\nresident_profile_rev <- resident_profile %>%\n  group_by(participantId) %>%\n  mutate(num_months = n_distinct(year_mth)) %>%\n  ungroup() %>%\n  filter(num_months == 12) %>%\n  select(-num_months, -Shelter, -RentAdjustment, -Wage)\n\n#output for dataframe using knitr:: kable\nkable(head(resident_profile_rev), \"simple\") \n\n\n\n\n\nparticipantId\nyear_mth\nCashflow\nage_group\neducationLevel\nhouseholdSize\nhaveKids\nIncome\nExpenses\nage\ninterestGroup\njoviality\njoviality_bins\nEducation\nFood\nRecreation\nShelter_new\n\n\n\n\n0\n2022-03\n10722.01\n30-39\nHighSchoolOrCollege\n3\nTRUE\n11931.95\n1209.94\n36\nH\n0\n(0,0.2]\n38.01\n268.26\n348.68\n554.99\n\n\n0\n2022-04\n7558.67\n30-39\nHighSchoolOrCollege\n3\nTRUE\n8636.88\n1078.21\n36\nH\n0\n(0,0.2]\n38.01\n265.79\n219.42\n554.99\n\n\n0\n2022-05\n7807.63\n30-39\nHighSchoolOrCollege\n3\nTRUE\n9048.16\n1240.53\n36\nH\n0\n(0,0.2]\n38.01\n264.54\n382.99\n554.99\n\n\n0\n2022-06\n7732.59\n30-39\nHighSchoolOrCollege\n3\nTRUE\n9048.16\n1315.57\n36\nH\n0\n(0,0.2]\n38.01\n256.90\n465.67\n554.99\n\n\n0\n2022-07\n6704.27\n30-39\nHighSchoolOrCollege\n3\nTRUE\n8636.88\n1932.61\n36\nH\n0\n(0,0.2]\n38.01\n270.13\n1069.48\n554.99\n\n\n0\n2022-08\n8290.55\n30-39\nHighSchoolOrCollege\n3\nTRUE\n9459.44\n1168.89\n36\nH\n0\n(0,0.2]\n38.01\n261.76\n314.13\n554.99"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#interactive-dashboard",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#interactive-dashboard",
    "title": "Take Home Exercise 1",
    "section": "4.1 Interactive Dashboard",
    "text": "4.1 Interactive Dashboard\nA dashboard is created to provide an overview of the demographics of residents in City of Engagement across age group. Bar chart is chosen to show segments of information by comparing different categorical variables. A design layout is included in the code to better visualized the output through patchwork. Moreover, tooltip is used to highlight the specific age group at the point of the data.\n\n\nShow the code\n#Create new df by doing a full join with participants_counts\nparticipants_new_rev <- full_join(\n  participants_new, participant_counts, \n  by = c(\"participantId\" = \"participantId\"))  %>%\n  group_by(participantId) %>%\n  #participants_counts contains the number of months the participants entries are in\n  ungroup() %>%\n  #filter away participantsId who do not have entries for the full year\n  filter(num_months == 12) %>%\n  select(-num_months)\n\n#create tooltip to display age group \nparticipants_new_rev$tooltip <-c(paste0(\n  \"Age Group:\", participants_new_rev$age_group))\n\n#Bar chart for resident's age distribution\np1 <- ggplot(data= participants_new_rev,\n      aes(x = age_group)) +\n      geom_bar_interactive(aes(tooltip = participants_new_rev$tooltip, \n                               stackgroups = TRUE,\n                               data_id= age_group)) + \n      scale_fill_manual(values = wes_palette(\"Chevalier1\")) +\n      xlab(\"Age Group\") +\n      ylab(\"No. of participants\") +\n      theme(axis.text.x=element_text(size=5)) +\n      theme(axis.title.y=element_text(size=10)) +\n      ylim(0,250)\n\n#Bar chart for resident's household size distribution\np2 <- ggplot(data= participants_new_rev,\n      aes(x = householdSize)) +\n      geom_bar_interactive(aes(tooltip = participants_new_rev$tooltip, \n                               stackgroups = TRUE,\n                               data_id= age_group)) +\n      scale_fill_manual(values = wes_palette(\"Chevalier1\")) +\n      xlab(\"Size of Household\") +\n      ylab(\"\") +\n      theme(axis.text.x=element_text(size=5)) +\n      theme(axis.title.y=element_text(size=10)) +\n      ylim(0,350)\n\n\n#Bar chart for resident's education level\np3 <- ggplot(data= participants_new_rev,\n      aes(x = educationLevel)) +\n      geom_bar_interactive(aes(tooltip = participants_new_rev$tooltip, \n                               stackgroups = TRUE,\n                               data_id= age_group)) +\n      xlab(\"Education Level\") +\n      ylab(\"\") +\n      theme(axis.text.x=element_text(size=5)) +\n      theme(axis.title.y=element_text(size=10)) +\n      ylim(0,350)\n\n#Bar chart to visualize if residents have kids \np4 <- ggplot(data= participants_new_rev,\n      aes(x = haveKids)) +\n      geom_bar_interactive(aes(tooltip = participants_new_rev$tooltip, \n                               stackgroups = TRUE,\n                               data_id= age_group)) +\n      ylab(\"\") +\n      theme(axis.text.x=element_text(size=5)) +\n      theme(axis.title.y=element_text(size=10)) +\n      ylim(0,400)\n\n#Bar chart for residents' interest group \np5 <- ggplot(data= participants_new_rev,\n      aes(x = interestGroup)) +\n      geom_bar_interactive(aes(tooltip = participants_new_rev$tooltip, \n                               stackgroups = TRUE,\n                               data_id= age_group)) +\n      xlab(\"Interest Group\") +\n      ylab(\"No. of participants\") +\n      theme(axis.text.x=element_text(size=5)) +\n      theme(axis.title.y=element_text(size=10)) +\n      ylim(0,120)\n\n#Bar chart for residents' joviality in bins \np6 <- ggplot(data= participants_new_rev,\n      aes(x = joviality_bins)) +\n      geom_bar_interactive(aes(tooltip = participants_new_rev$tooltip, \n                               stackgroups = TRUE,\n                               data_id= age_group)) +\n      xlab(\"Joviality\") +\n      ylab(\"No. of participants\") +\n      theme(axis.text.x=element_text(size=5)) +\n      theme(axis.title.y=element_text(size=10)) +\n      ylim(0,250)\n\n#design layout for the patchwork figure\ndesign <- \"\n  132\n  132\n  554\n  554\n  666\n  666\n\"\n\ngirafe(code = print(p1 + p2 + p3 + p4 + p5  + p6 +\n                      plot_layout(design = design,) + \n                      plot_annotation(title = \n                    \"Demographics Insights of residents in City of Engagement\",\n                     theme = theme(plot.title = element_text(size = 20, hjust=0.5))\n                      )), \n       width_svg = 12,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #02401B;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\nObservations:\n\nThe city might be facing an aging population as age group is left-skewed.\nLow interest for future education as education level is right-skewed.\nSmall family size with higher proportion of participants of not having Kids.\nUniformly distributed Interest Group. No preference among age group.\nJoviality level seems to be decreasing at a decreasing rate\n\n\n\n\n\n\n\nInteractivity\n\n\n\nClick on the graph and hover around each demographics.\nThe respective age group will be displayed."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#financial-health-of-participants",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#financial-health-of-participants",
    "title": "Take Home Exercise 1",
    "section": "4.2 Financial Health of Participants",
    "text": "4.2 Financial Health of Participants\nTo know more about the financial health of the participants, interactive geom_point is used to plot against the time period. tooltip is included to create a snapshot of the financial health status of the participants at the time period.\nscale_color_manual of [ggplot2] is used to differentiate between positive and negative cash flow. In addition, the plot contains hover effect with the use of data_id aesthetic to highlight the trend of the participant’s cash flow.\n\n\nShow the code\n#tooltip output to display ID, Cashflow, Income, and Expenses\nresident_profile_rev$tooltip <- paste0(\n  \"Participant's ID = \", resident_profile_rev$participantId,\n  \"\\n Cashflow = \", format(resident_profile_rev$Cashflow, big.mark = \",\"),\n  \"\\n Income = \", format(resident_profile_rev$Income, big.mark = \",\"),\n  \"\\n Expenses = \", format(resident_profile_rev$Expenses, big.mark = \",\")\n                                  )\n#tool_tip design\ntooltip_css <- \"background-color: lightgrey; #<<\nfont-style:bold; color: #446455;\" #<<\n\nie <-  ggplot(data=resident_profile_rev) +\n       geom_point_interactive(aes(x = year_mth, y = Cashflow,\n                                   tooltip = resident_profile_rev$tooltip,\n                                   data_id = participantId,\n                                   #if Cashflow >0 = Green, else Red\n                                   color = ifelse(Cashflow >= 0, \n                                                  \"Above 0\", \"Below 0\")\n                                   )) +\n        scale_color_manual(values = c(\"Above 0\" = \"#446455\", \n                                      \"Below 0\" = \"#C93312\")) +\n        #remove legend title \n      labs(color = \"\") +\n      labs(title=\"Financial Health of Participants from Mar 2022 to Feb 2023\") +\n      ylab(\"Cashflow ($)\") + xlab(\"Year-month\") +  \n      scale_y_continuous(labels = comma_format()) +\n      theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n      theme_minimal()        |>\n\ngirafe(                                  \n  ggobj = ie,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list( #<<\n    opts_tooltip(css = tooltip_css), #<<\n    opts_hover_inv(css = \"opacity:0.1;\") #<<\n  )                                        \n)   \n\n\n\n\n\n\nObservations:\n\nMajority of participants have positive cash flow (Good Credit Rating)\nNegligible growth on cash flow\nNo drastic changes in participant’s cash flow over time"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#the-circulation-of-money",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#the-circulation-of-money",
    "title": "Take Home Exercise 1",
    "section": "4.3 The Circulation of Money",
    "text": "4.3 The Circulation of Money\nAs illustrated earlier, the cash flow is a holding transaction. It is holded by the individual after repaying the necessary debt/expenses. To build more wealth, it is ideal for Wage to increase or for expenses to decrease.\nWith that in mind, a line scatter pot is used to identify the trend in various categories over a time period. The participants dataset have been revised to exclude participants who did not fulfill the entries check. It has been reformatted before executing a full_join with participants_count data set. The joined table concatenates the count of the year-mth period (num_months) that is not available in the dataset and filters it away.\nThe plot_ly() graph below shows the total amount circulated by the participants.\n\n\nShow the code\n#to reformat partcipantId, create year-mth, round off amount to 2.d.p\nfinancial_journal_lessdup <- financial_journal_lessdup %>%\n  mutate(participantId = as.character(participantId),\n        year_mth = format(as.Date(financial_journal_lessdup$timestamp), \"%Y-%m\",\n        amount = abs(round(amount,2)),\n        .before = 1)) \n\n#Create new df by doing a full join with participants_counts\nfinancial_journal_lessdup_lessentries <- full_join(\n  financial_journal_lessdup, participant_counts, \n  by = c(\"participantId\" = \"participantId\"))  %>%\n  group_by(participantId) %>%\n  #participants_counts contains the number of months the participants entries are in\n  mutate(num_months = n_distinct(year_mth)) %>%\n  ungroup() %>%\n  #filter away participantsId who do not have entries for the full year\n  filter(num_months == 12) %>%\n  select(participantId, year_mth, category,amount)\n\n#create another df to group by year_mth, category\ngrouped_data_rev <- financial_journal_lessdup_lessentries %>%\n  #group the columns in the following order \n  group_by(year_mth, category) %>%\n  summarize(total_amount = sum(amount)) \n\n#creating interactive graph\nplot_ly(data = grouped_data_rev, \n  x = ~year_mth, y = ~total_amount, color = ~category,\n  type = 'scatter', mode = 'line',\n  hovertemplate = ~paste(\"Year-Month:\", year_mth,\n                         \"<br>Amount:\", format(total_amount, big.mark = \",\"))) |>\n\n#Configure title and axes\n  layout(title = \"The Circulation of Money\",\n         xaxis = list(title = \"Time Period\"),\n         yaxis = list(title = \"Amount\"))\n\n\n\n\n\n\nObservations:\n\nIncome (~Wage) is fairly constant except for Mar 2022. It can be inferred that the spike in Wage could be a form of bonus, grant, incentives given by the service centre and might not be an one off special event (requires longer time period to determine).\nExpenses distribution seems to be constant with lesser spending on Education expenses . However, there is a slight fluctuation in Recreation expenses.\n\n\n4.3.1 Spending Patterns of participants\nAs observed earlier, there are a slight fluctuation in Recreation expenses. Henceforth, Wage will be removed in the graph to better visualize the expenses.\nPlot_ly graph is plotted to visualize the spending patterns.\n\n\nShow the code\n#create a new dataset\ngrouped_data_rev_new <- financial_journal_lessdup_lessentries %>%\n  mutate(amount = abs(round(amount,2))) %>%\n  #group the columns in the following order \n  group_by(category,year_mth) %>%\n  summarize(total_amount = sum(amount)) \n\n# Filter out \"Wage\" category from the data frame\ngrouped_data_rev_newest <- grouped_data_rev_new %>% \n   filter(category != \"Wage\")\n\n#creating interactive graph\nplot_ly(data = grouped_data_rev_newest, \n  x = ~year_mth, y = ~total_amount, color = ~category,\n  type = 'scatter', mode = 'line',\n  hovertemplate = ~paste(\"Year-Month:\", year_mth,\n                         \"<br>Amount:\", format(total_amount, big.mark = \",\"))) |>\n\n#Configure title and axes\n  layout(title = \"Spending Patterns of participants from Mar 2022 - Feb 2023\",\n         xaxis = list(title = \"Time Period\"),\n         yaxis = list(title = \"Total Expenses\"))\n\n\n\n\n\n\nObservations:\n\nEducation remain constant throughout while Shelter decrease in Mar 2022 and remains constant. Both expenses are a fixed expense.\nRecreation expenses fluctuates more in comparison to Food expenses."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#association-test-between-age-group-and-education-level",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#association-test-between-age-group-and-education-level",
    "title": "Take Home Exercise 1",
    "section": "5.1 Association Test between Age group and Education Level",
    "text": "5.1 Association Test between Age group and Education Level\nAs observed in Section 4.1 - Interactive Dashboard, we noticed that the age-group is left-skewed while the education level is right-skewed. Therefore, we would like to test if there is any association between the two variables. Notably, the association test is non-parametric and thus, does not have to conform to the normality assumption.\nAt 95% confidence level,\nHo : No association exists between the age group and education level\nH1: Association exists between the age group and education level\n\n\nShow the code\nggbarstats(data = resident_profile_rev, \n           x = educationLevel, y = age_group,\n           xlab= \"Age Group\", ylab = \"Education Level\",\n           title = \"Comparison of Education level across Age Group\",\n           type = \"nonparametric\", conf.level = 0.95,\n           package = \"wesanderson\", palette = \"Chevalier1\"\n           )\n\n\n\n\n\nFrom the graph, we observed that majority of the age group have a HighSchoolOrCollege education level. Likewise, we also note that the interest for further education decreases as the age increases. Interestingly, young adults aged 20-29 have attained a higher education level than any other age group.\nFrom the test result above (p<0.05) , we conclude that there is an association between the age group and education level as we reject the null hypothesis."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#differences-in-joviality-based-on-education-levelage-group",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#differences-in-joviality-based-on-education-levelage-group",
    "title": "Take Home Exercise 1",
    "section": "5.2 Differences in Joviality based on Education Level/Age Group",
    "text": "5.2 Differences in Joviality based on Education Level/Age Group\nAs defined earlier, Joviality indicates the participant’s overall happiness at the start of the study. We will like to found out if there is a difference in Joviality based on Education Level. Before testing our hypothesis, we will perform a normality assumption test at 95% confidence level.\n\n5.2.1 Normality Assumption Test\nThe statistical graph - Normal Quantile Plot (QQ Plot) is used to visualize a normal distribution as it shows the type of distribution. To be normally distributed, the dot points should be scatter very closely to the slope line. However, as seen from bottom left figure, the dot points curve. Therefore, by the data visualization alone, we can visually confirmed that the observed values failed to conform to the normality assumption.\nTo confirm our data visualization, we perform an Anderson-Darling normality test.\nAt 95% confidence level:\nHo: the observed distribution resembles normal distribution\nH1: the observed distribution failed to resemble normal distribution\n\n\n\n\n\n\n\nShow the code\n#Anderson-Darling normality test\nad_test <- ad.test(resident_profile_rev$joviality)\n\n# QQ plot\nqq <- ggplot(data = resident_profile_rev, \n             aes(sample = joviality)) +\n      stat_qq() +\n      stat_qq_line() \n          \n# Create a data frame with ad_test result\ntable_data <- data.frame(\n      Test = \"Anderson-Darling\",\n      Statistic = ad_test$statistic,\n      p_value = ad_test$p.value\n      )\n\n# Save plot and table as png image\npng(\"qq_plot_with_table.png\", height = 500, width= 900, units =\"px\")\ngrid.arrange(qq, tableGrob(table_data), nrow = 1, \n                 top = text_grob(\"Normality Quantile Plot with Anderson-Darling Normality Test\", size =10))\n\n#display output using knitr \nknitr::include_graphics(\"qq_plot_with_table.png\")\n\n\n\n\n\nBased on the result above, we concluded that there is enough statistical evidence to reject the null hypothesis. Since the p-values fall below (p < 0.05), normality is not assumed. Henceforth, we will use the non-parametric test to conduct our analysis.\n\n\n5.2.2 Kruskal-Wallis Test for Joviality across Education Level\nWe will test the following hypothesis at 95% Confidence Level:\nHo : the median Joviality across different education level is the same\nH1: the median Joviality across different education level is not the same\n\n\nShow the code\nggbetweenstats(data = resident_profile_rev,\n       x= educationLevel, y= joviality, type =\"np\",\n       xlab= \"Education Level\", ylab = \"Joviality\",\n       title = \"Comparison of Joviality across Education Level\",\n       pairwise.comparisons = TRUE, pairwise.display =\"ns\", conf.level = 0.95,\n       package = \"wesanderson\", palette = \"Chevalier1\"\n       )\n\n\n\n\n\nAs observed from the test results above, the P-value is lower than the 0.05. As such, there is enough statistical evidence to reject the null hypothesis that the median joviality across education level is the same.\nAdditionally, we want to find out if there any distinct similarities between the district. From the figure above, we discovered that not all pair comparison are statistically significant. The pair (Low and HighSchoolOrCollege) is not statistically significant with a P-value of 0.08, which is greater than 0.05. Thus, we cannot reject the null hypothesis that there is not differences between the joviality level between the pair.\n\n\n5.2.3 Plotting Confidence Interval of Point Estimates\nstat_pointinterval() of [ggdist] package is used to visualize the distribution of confidence interval by education level. Due to skewness of data, the median point estimate are used. To distinguish between the interval, scale_color_manual() of [ggplot2] is used (Note: color contrast is added) .\n\n\nShow the code\n#plot points and intervals \nggplot(data = resident_profile_rev, \n       aes(x = educationLevel, y = joviality)) +\n  stat_pointinterval(aes(interval_color = after_stat(level)),\n                     point_interval = \"median_qi\",\n                     .width = c(0.95,0.99),\n                     point_color = \"#C93312\") +\n  labs(title = \"Visualizing Confidence Intervals of Median Joviality\", \n       x = \"Education Level\", y = \"Joviality\") +\n#add colors to graph \n  scale_color_manual(values = c(\"#D3DDDC\",\"#446455\"), \n                     aesthetics = \"interval_color\") +\n\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) \n\n\n\n\n\nAs seen above, the are high uncertainty across the education level, with an increase in median estimate. This suggests that there might be large presence of outliers in each education level.\n\n\n5.2.4 Kruskal-Wallis Test for Joviality across Age Group\nEarlier, we discovered that there is a statistical difference in joviality across Education Level, we would like to examine if the same applies across age group. As per section 5.2.1, normality is not assumed. Thus, we will use non-parametric test to conduct our analysis.\nWe will test the following hypothesis at 95% Confidence Level:\nHo : the median Joviality across the age group is the same\nH1: the median Joviality across the age group is not the same\n\n\nShow the code\nggbetweenstats(data = resident_profile_rev,\n       x= age_group, y= joviality, type =\"np\",\n       xlab= \"Age Group\", ylab = \"Joviality\",\n       title = \"Comparison of Joviality across Age Group\",\n       pairwise.comparisons = TRUE, pairwise.display =\"ns\", conf.level = 0.95,\n       package = \"wesanderson\", palette = \"Chevalier1\"\n       )\n\n\n\n\n\nAs observed from the test results above, the P-value is lower than the 0.05. As such, there is enough statistical evidence to reject the null hypothesis that the median joviality across age group is the same.\nFrom the figure above, we discovered that not all pair comparison are statistically significant as there are two pairs with p-value greater than 0.05. The pairs (age group 20-29 and age group 30-39) and (age group 30-39 and age group 40-49) are not statistically significant with a P-value of 0.36 and 0.20 respectively. Thus, we cannot reject the null hypothesis that there is not differences between the joviality level between the pairs."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#differences-in-joviality-based-on-income",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#differences-in-joviality-based-on-income",
    "title": "Take Home Exercise 1",
    "section": "5.3 Differences in Joviality based on Income",
    "text": "5.3 Differences in Joviality based on Income\nWe will like to found out if there is a difference in Joviality based on Income. A plot_ly() graph is use to graph. Opacity is included to highlight the contrast and a hovertemplate is included to reflect the <participantID>, <Cashflow>, <Income>, and Expenses .\n\n\nShow the code\nplot_ly(data = resident_profile_rev, \n             x = ~joviality, y = ~Income,\n        hovertemplate = ~paste(\"<br>Participant's ID:\",participantId,\n                               \"<br>Cashflow:\", Cashflow,\n                              \"<br>Income:\", Income,\n                               \"<br>Expenses:\", Expenses),\n             \n            type = \"scatter\",\n            mode = \"markers\",\n            marker = list(opacity = 0.7,sizemode = \"diameter\", \n                          line = list(width =0.1, color = \"white\"))) |>\n\n#add title and labels to axis \n        layout(title = \"Income vs Joviality\" ,\n         xaxis = list(title = \"Joviality level\") ,\n         yaxis = list(title = \"Income\"))\n\n\n\n\n\n\nObservations:\n\nJoviality level decreases as income level increases. It decreases sharply when income exceeds $15k.\nSimilar to income range of $10-$15k where majority have low joviality\nJoviality level are more spread out when income ranges below $5k\n\n\n5.3.1 Correlation Analysis between Joviality and Income\nSince joviality is not normally distributed, a ggscatterstats() from [ggstatsplot] is used to build a visual for Significant Test of Correlation between Joviality and Income.\n\n\nShow the code\nggscatterstats(\n  data = resident_profile_rev,\n  x = joviality, y = Income,\n  type = \"nonparametric\", marginal = TRUE,\n  title = \"Significant Test of Correlation between Joviality and Income\",\n  xlab = \"Joviality\",\n  ylab = \"Income\"\n)\n\n\n\n\n\nThe test result of The Spearman correlation coefficient indicates that the there is a weak negative linear relationship between Joviality and Income. Even though the correlation is on the weaker end, we can conclude that there is an inverse relationship between them. The higher you earn, the lower your joviality.\n\n\n\n\n\n\nCorrelation Coefficient\n\n\n\nTo interpret the values of correlation (-1 <= x<= 1),\n\n‘+’ reflects a positive linear relationship\n‘-’ reflects a negative linear relationship\nA value of <0.3 is weak, 0.5 is moderate, >0.8 is strong, and 1 is perfect"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#factors-affecting-cash-flow",
    "href": "Take-Home_Ex/Take_Home_Ex01/Take-Home_Ex01.html#factors-affecting-cash-flow",
    "title": "Take Home Exercise 1",
    "section": "5.4 Factors affecting Cash flow",
    "text": "5.4 Factors affecting Cash flow\nNotably, the circulation of money is crucial for City of Engagement and could potentially impact the Local Plan 2023 that is in the midst of preparation. Henceforth, we would like to into the correlation between income and expenses across education level.\n\n5.4.1 Cash flow vs Income across Education Level\nMultiple ggscatterstats() from [ggstatsplot] is used to build a visual for Significant Test of Correlation between Cashflow and Income by filtering the education level. patchwork is included to combine the graphs.\n\n\nShow the code\n#plotting correlation between cashflow and income across education level\nedu_low <- ggscatterstats(data = resident_profile_rev |> \n                           filter(educationLevel == \"Low\"), \n                           x = Income, y = Cashflow,\n                           type = \"nonparametric\") + \n           theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n           labs(title = \"Low\", \n           x = \"Income\", y = \"Cash flow\") +\n           scale_y_continuous(labels = comma_format()) \n\nedu_hc <- ggscatterstats(data = resident_profile_rev |> \n                           filter(educationLevel == \"HighSchoolOrCollege\"), \n                           x = Income, y = Cashflow,\n                           type = \"nonparametric\") + \n          theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n          labs(title = \"High School\", \n          x = \"Income\", y = \"Cash flow\") +\n          scale_y_continuous(labels = comma_format()) \n\nedu_bach <- ggscatterstats(data = resident_profile_rev |> \n                           filter(educationLevel == \"Bachelors\"), \n                           x = Income, y = Cashflow,\n                           type = \"nonparametric\") + \n            theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n            labs(title = \"Bachelors\", \n            x = \"Income\", y = \"Cash flow\") +\n            scale_y_continuous(labels = comma_format()) \n\nedu_grad <- ggscatterstats(data = resident_profile_rev |> \n                           filter(educationLevel == \"Graduate\"), \n                           x = Income, y = Cashflow,\n                           type = \"nonparametric\") + \n            theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n            labs(title = \"Graduate\", \n            x = \"Income\", y = \"Cash flow\") +\n            scale_y_continuous(labels = comma_format()) \n\n#combined plot and ensure layout is in order\ncorr_edu <- ((edu_low + edu_hc) / (edu_bach + edu_grad) + plot_spacer())\n\n#add labels\ncorr_edu + plot_annotation(title = \"Correlation between Cashflow and Income\", \n                           subtitle = \"High correlation between Cashflow and Income at all education level\",\n                           theme = theme(\n                             plot.title = element_text(size = 18),\n                             plot.subtitle = element_text(size = 12)))\n\n\n\n\n\nAs seen above, there is an almost perfect positive linear relationship (>0.9) between Cash flow and Income across Education level. The Spearman correlation coefficient also increases at different education level.\n\n\n5.4.2 Cash flow vs Expenses across Education Level\nSimilar approach to the previous section.\n\n\nShow the code\n#plotting correlation between expenses and cashflow across education level\nedu_low_ex <- ggscatterstats(data = resident_profile_rev |> \n                           filter(educationLevel == \"Low\"), \n                           x = Expenses, y = Cashflow,\n                           type = \"nonparametric\") + \n           theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n           labs(title = \"Low\", \n           x = \"Expenses\", y = \"Cash flow\") +\n           scale_y_continuous(labels = comma_format()) \n\nedu_hc_ex <- ggscatterstats(data = resident_profile_rev |> \n                           filter(educationLevel == \"HighSchoolOrCollege\"), \n                           x = Expenses, y = Cashflow,\n                           type = \"nonparametric\") + \n          theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n          labs(title = \"High School\", \n          x = \"Expenses\", y = \"Cash flow\") +\n          scale_y_continuous(labels = comma_format()) \n\nedu_bach_ex <- ggscatterstats(data = resident_profile_rev |> \n                           filter(educationLevel == \"Bachelors\"), \n                           x = Expenses, y = Cashflow,\n                           type = \"nonparametric\") + \n            theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n            labs(title = \"Bachelors\", \n            x = \"Expenses\", y = \"Cash flow\") +\n            scale_y_continuous(labels = comma_format()) \n\nedu_grad_ex <- ggscatterstats(data = resident_profile_rev |> \n                           filter(educationLevel == \"Graduate\"), \n                           x = Expenses, y = Cashflow,\n                           type = \"nonparametric\") + \n            theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n            labs(title = \"Graduate\", \n            x = \"Expenses\", y = \"Cash flow\") +\n            scale_y_continuous(labels = comma_format()) \n\n#combined plot and ensure layout is in order\ncorr_edu <- ((edu_low_ex + edu_hc_ex) / (edu_bach_ex + edu_grad_ex) + \n               plot_spacer())\n\n#add labels\ncorr_edu + plot_annotation(title = \"Correlation between Cashflow and Expenses\", \n                           subtitle = \"Weak-to-moderate correlation between Cashflow and Expenses at all education level\",\n                           theme = theme(\n                             plot.title = element_text(size = 18),\n                             plot.subtitle = element_text(size = 12)))\n\n\n\n\n\nAs seen above, there is a negative linear relationship between Cash flow and Expenses across Education level. Low Education Level and Bachelors Education level have a weak-to-moderate correlation while HighSchoolOrCollege and Graduate have a weak negative linear relationship. Although the correlation is weak, we can still infer that the cashflow increases when expenses decreases.\n\n\n5.4.3 Correlation between Income and Expenses (Various Categories)\nNotably, we observed fluctuations in Recreation and Food expenses. Henceforth, we could like to know if there are any correlation between Income and various categories. Similarly, a ggscatterstats() from [ggstatsplot] is used to build a visual for Significant Test of Correlation between Income and Various Categories.\n\n\nShow the code\n#plotting correlation between income and various expenses\nin_food <- ggscatterstats(data = resident_profile_rev,\n                           x = Food, y = Income,\n                           type = \"nonparametric\") + \n           theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n           labs(title = \"Food\", \n           x = \"Food\", y = \"Income\") +\n           scale_y_continuous(labels = comma_format()) \n\nin_recreation <- ggscatterstats(data = resident_profile_rev,\n                           x = Recreation, y = Income,\n                           type = \"nonparametric\") + \n           theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n           labs(title = \"Recreation\", \n           x = \"Recreation\", y = \"Income\") +\n           scale_y_continuous(labels = comma_format())\n\nin_shelter <- ggscatterstats(data = resident_profile_rev,\n                           x = Shelter_new, y = Income,\n                           type = \"nonparametric\") + \n           theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n           labs(title = \"Shelter\", \n           x = \"Shelter\", y = \"Income\") +\n           scale_y_continuous(labels = comma_format()) \n\nin_education <- ggscatterstats(data = resident_profile_rev,\n                           x = Education, y = Income,\n                           type = \"nonparametric\") + \n           theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n           labs(title = \"Education\", \n           x = \"Education\", y = \"Income\") +\n           scale_y_continuous(labels = comma_format()) \n\n#combined plot and ensure layout is in order\ncorr_income <- ((in_recreation + in_food) / (in_shelter + in_education) + \n               plot_spacer())\n\n#add labels\ncorr_income + plot_annotation(title = \"Correlation between Income and various Expenses\", \n                           subtitle = \"Weak correlation between Income and various Expenses at all education level\", \n                           theme = theme(\n                             plot.title = element_text(size = 18),\n                             plot.subtitle = element_text(size = 12)))\n\n\n\n\n\nFrom the results above, we noticed that all categories have a weak negative linear relationship with Income. Despite the fact that Education and Shelter belongs to fixed expenses whereas Recreation and Food are variable expenses, the correlation coefficient results prove otherwise."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#install-r-packages",
    "href": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#install-r-packages",
    "title": "Take Home Exercise 3",
    "section": "3.1 Install R-packages",
    "text": "3.1 Install R-packages\nUsing p_load() of pacman package to load and install the following libraries:\n\npacman::p_load(jsonlite, tidygraph, ggraph, \n               visNetwork, graphlayouts, ggforce, \n               skimr, tidytext, tidyverse, DT)\noptions(scipen = 999)"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#importing-data",
    "href": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#importing-data",
    "title": "Take Home Exercise 3",
    "section": "3.2 Importing Data",
    "text": "3.2 Importing Data\nImporting JSON file by using jsonlite package.\n\nMC3_challenge <- fromJSON(\"data/MC3.json\")\n\nThis is not a directed graph. There is no flow by degree (directed = FALSE)\n\n3.2.1 Extracting Edges\nAs the imported data file is a large list, we will extract the edges from MC3_challenge and save it as a tibble data frame called MC3_edges. The code is extracted in the following manner:\n\ndistinct() is used to remove duplicated records\nmutate() and as.character() are used to convert field data type from list to character\ngroup_by() and summarise() are used to count the number of unique links\nfilter(source!=target) is used to ensure that both companies are not identical\n\n\n\nShow the code\nMC3_edges <-as_tibble(MC3_challenge$links) %>%\n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source,target, type) %>%\n  summarise(weights = n()) %>%\n  filter (source != target) %>%\n  ungroup()\n\n\n\n\n3.2.2 Extracting Nodes\nSimilarly, we will extract the nodes from MC3_challenge and save it as a tibble data frame called MC3_nodes. The code is extracted in the following manner:\n\nmutate() and as.character() are used to convert data type from list to character\nas.numeric(as.character()) are used to convert revenue_omu from list to character before converting it to numeric data type.\nselect() is used to reorganize the sequence\n\n\nMC3_nodes <-as_tibble(MC3_challenge$nodes) %>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n  select(id,country,type,revenue_omu,product_services)"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#exploring-the-edges-data-frame",
    "href": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#exploring-the-edges-data-frame",
    "title": "Take Home Exercise 3",
    "section": "4.1 Exploring the edges data frame",
    "text": "4.1 Exploring the edges data frame\nskim() of [skimr] package is used to display the summary statistic of MC3_edges tibble data frame. As observed, there are not missing values in all fields.\n\nskim(MC3_edges)\n\n\nData summary\n\n\nName\nMC3_edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\ndatatable() of the [DT] package is used to display MC3_edges tiddle data frame as an interactive table.\n\nDT::datatable(MC3_edges)\n\n\n\n\n\n\n\n4.1.1 Plotting bar chart\n\nggplot(data = MC3_edges,\n       aes(x= type)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#exploring-the-nodes",
    "href": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#exploring-the-nodes",
    "title": "Take Home Exercise 3",
    "section": "4.2 Exploring the nodes",
    "text": "4.2 Exploring the nodes\nskim() of [skimr] package is used to display the summary statistic of MC3_nodes tibble data frame. As observed, there are not missing values in all fields.\n\nskim(MC3_nodes)\n\n\nData summary\n\n\nName\nMC3_nodes\n\n\nNumber of rows\n27622\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n6\n64\n0\n22929\n0\n\n\ncountry\n0\n1\n2\n15\n0\n100\n0\n\n\ntype\n0\n1\n7\n16\n0\n3\n0\n\n\nproduct_services\n0\n1\n4\n1737\n0\n3244\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrevenue_omu\n21515\n0.22\n1822155\n18184433\n3652.23\n7676.36\n16210.68\n48327.66\n310612303\n▇▁▁▁▁\n\n\n\n\n\n\nDT:: datatable(MC3_nodes)\n\n\n\n\n\n\n\n4.2.1 Plotting the bar chart\n\nggplot(data = MC3_nodes,\n       aes(x=type)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#building-network-model-with-tidygraph",
    "href": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#building-network-model-with-tidygraph",
    "title": "Take Home Exercise 3",
    "section": "5. 1 Building network model with tidygraph",
    "text": "5. 1 Building network model with tidygraph\n\nid1 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- MC3_edges %>%\n  select(target) %>%\n  rename(id = target)\nMC3_nodes_master <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(MC3_nodes,\n            unmatched = \"drop\")\n\n\nMC3_graph <- tbl_graph(nodes = MC3_nodes_master,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\nMC3_graph %>%\n  filter(betweenness_centrality >= 100000) %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#simple-word-count",
    "href": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#simple-word-count",
    "title": "Take Home Exercise 3",
    "section": "6.1 Simple Word count",
    "text": "6.1 Simple Word count\n\nMC3_nodes %>%\n  mutate(n_fish = str_count(product_services, \"fish\"))\n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   <chr>                       <chr>   <chr>       <dbl> <chr>             <int>\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#tokenisation",
    "href": "Take-Home_Ex/Take_Home_Ex03/Take-Home_Ex03.html#tokenisation",
    "title": "Take Home Exercise 3",
    "section": "6.2 Tokenisation",
    "text": "6.2 Tokenisation\nTokenisation refers to the process of breaking up a given text into units called tokens. It could be individual words, phrases or the entire sentences. unnest_tokens() is used. The unnested text goes to the output column - word after extracting it from product_services.\n\ntoken_nodes <- MC3_nodes %>%\n  unnest_tokens(word, \n                product_services)\n\n\n6.2.1 Visualizing the Extracted words\n\ntoken_nodes %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\n\n\n6.3 Removing stopwords\n\nstopwords_removed <- token_nodes %>% \n  anti_join(stop_words)\n\nstopwords_removed %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\nGiven that there are 7750 unique texts in the word columnwe will focus on the words that are related to illegal fishing.\n\nlength(unique(stopwords_removed$word))\n\n[1] 7750\n\n\n\n#create custom stop words vector\ncustom_stopwords <- c(\"food\")\n\nclean_text <- stopwords_removed %>%\n  filter(!word %in% custom_stopwords) %>%\n  filter(!grepl(\"\\\\d\", word)) %>%  #to remove numbers \n  filter(grepl(\"fish\", word) | grepl(\"seafood\", word ) | grepl(\"shrimp\", word)) \n\n\n#  mutate(category = case_when(\n#    grepl(\"products\", word, ignore.case= TRUE) ~ \"Products\",\n#    grepl(\"services\", word, ignore.case = TRUE) ~ \"Services\",\n#    TRUE ~ 'Others'))\n\nclean_text %>%\n  count(word, sort = TRUE) %>%\n  top_n(20) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "FishEye International is collaborating with the country of Oceanus to identify companies who could potentially engaged in illegal, unreported, and unregulated (IUU) fishing. FishEye has transformed import/export data into a knowledge graph.\nThe country of Oceanus has sought FishEye International’s help in identifying companies possibly engaged in illegal, unreported, and unregulated (IUU) fishing. 12 groups of link suggestions with various fish types are used to reason on the knowledge graph.\n\n\nIn this take-home exercise, temporal patterns for individual entries and between entities are identified using the knowledge graph FishEye created from trade records. In addition, we evaluate the sets of predicted knowledge graph links (Bundles) to determine which sets are more reliable in completing the graph."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#metadata",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#metadata",
    "title": "Take Home Exercise 2",
    "section": "2.1 Metadata",
    "text": "2.1 Metadata\n\n\n\n\n\n\n\n\nLocation\nVariables Name\nDescription\n\n\n\n\nNode\nid\nName of the company that originated (or received) the shipment\n\n\nNode\nshpcountry\nCountry the company most often associated with when shipping\n\n\nNode\nrcvcountry\nCountry the company most often associated with when receiving\n\n\nNode, Edge\ndataset\nAlways ’MC2\n\n\nEdge\narrivaldate\nDate the shipment arrived at port in YYYY-MM-DD format.\n\n\nEdge\nhscode\nHarmonized System code for the shipment.\n\n\nEdge\nvalueofgoods_omu\nCustoms-declared value of the total shipment, in Oceanus Monetary Units (OMU)\n\n\nEdge\nvolumeteu\nThe volume of the shipment in ‘Twenty-foot equivalent units’\n\n\nEdge\nweightkg\nThe weight of the shipment in kilograms\n\n\nEdge\ntype\nAlways ‘shipment’ for MC2\n\n\nEdge\ngenerated_by\nName of the program that generated the edge (only in bundles)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHS code, also known as The Harmonized System are alphanumeric codes used for classifying goods for international trade and customs purposes. It composed of six digits and could be broken down into chapter/heading/subheading (two digits each)."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#install-r-packages",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#install-r-packages",
    "title": "Take Home Exercise 2",
    "section": "3.1 Install R-packages",
    "text": "3.1 Install R-packages\nUsing p_load() of pacman package to load and install the following libraries:\n\njsonlite : To import data from JSON File into R\nlubridate : To convert Date and Time\nvisNetwork: For Network Visualization\ntidyverse: A collection of R packages use in everyday data analyses. It is able to support data science, data wrangling, and analysis.\nhrbrthemes: For Additional Themes, and Utilities for ‘ggplot2’ (might not use)\nheatmaply: For creating Interactive Cluster Heatmaps\ntreemap: For viisualizing hierarchical data using nested rectangles\ndevtools: For the installing for d3treeR\nigraph: For exploring the network\nRColorBrewer: For visualization. Contains ready-to-use color palettes\nknitr: For dynamic report generation\nstringr: For character manipulation.\n\n\npacman :: p_load (jsonlite, lubridate, tidygraph, ggraph, visNetwork, tidyverse,\n                  igraph,heatmaply,hrbrthemes,treemap,devtools,\n                  ggstatsplot,RColorBrewer, knitr,stringr)\n\noptions(scipen = 999)"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#importing-data",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#importing-data",
    "title": "Take Home Exercise 2",
    "section": "3.2 Importing Data",
    "text": "3.2 Importing Data\nThe JSON files will be imported into R with the use of fromJSON function from jsonlite. The code chunk below shows the knowledge graph FishEye created from trade records.\n\nMC2_challenge <- fromJSON(\"data/mc2_challenge_graph.json\")\n\nThe bundles which consists of Carp, Catfish, Chub_Mackerel, Cod2, Herring, Lichen, Mackerel, Pollock, Salmon_wgl, Salmon, Shark and Tuna are imported.\n\n\nShow the code\nMC2_carp <- fromJSON(\"data/bundles/carp.json\")\nMC2_catfish <- fromJSON(\"data/bundles/catfish.json\")\nMC2_chub_mackerel <- fromJSON(\"data/bundles/chub_mackerel.json\")\nMC2_cod2 <- fromJSON(\"data/bundles/cod2.json\")\nMC2_herring <- fromJSON(\"data/bundles/herring.json\")\nMC2_lichen <- fromJSON(\"data/bundles/lichen.json\")\nMC2_mackerel <- fromJSON(\"data/bundles/mackerel.json\")\nMC2_pollock <- fromJSON(\"data/bundles/pollock.json\")\nMC2_salmon_wgl <- fromJSON(\"data/bundles/salmon_wgl.json\")\nMC2_salmon <- fromJSON(\"data/bundles/salmon.json\")\nMC2_shark <- fromJSON(\"data/bundles/shark.json\")\nMC2_tuna <- fromJSON(\"data/bundles/tuna.json\")"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#create-tibble-data-frame",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#create-tibble-data-frame",
    "title": "Take Home Exercise 2",
    "section": "3.3 Create Tibble Data frame",
    "text": "3.3 Create Tibble Data frame\nAs the imported data is in JSON format, we will use the as_tibble to create a tibble from data.\n\nMC2_challenge_nodes <-as_tibble(MC2_challenge$nodes) %>%\n  select(id,shpcountry,rcvcountry)\nMC2_challenge_edges <-as_tibble(MC2_challenge$links) %>%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg, valueofgoodsusd)\n\nAdditionally, the columns have been re-shuffled for the bundles. We used relocate to revise the order. The column will start from source, to target, etc. By doing so, every fish types have the same sequence.\n\n\nShow the code\n#1_fish type :carp\nMC2_carp_nodes <-as_tibble(MC2_carp$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_carp_edges <-as_tibble(MC2_carp$links) %>%\n  relocate(8,9,7,6)\n\n#2_fish type: catfish\nMC2_catfish_nodes <-as_tibble(MC2_catfish$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_catfish_edges <-as_tibble(MC2_catfish$links) %>%\n  relocate(6,7,5,4)\n\n#3_fish type: chub_mackerel\nMC2_chub_mackerel_nodes <-as_tibble(MC2_chub_mackerel$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_chub_mackerel_edges <-as_tibble(MC2_chub_mackerel$links) %>%\n  relocate(8,9,7,6)\n\n#4_fish type: cod2\nMC2_cod2_nodes <-as_tibble(MC2_cod2$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_cod2_edges <-as_tibble(MC2_cod2$links) %>%\n  relocate(8,9,7,6)\n\n#5_fish type: herring\nMC2_herring_nodes <-as_tibble(MC2_herring$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_herring_edges <-as_tibble(MC2_herring$links) %>%\n  relocate(7,8,6,5,1,2,9,3,4)\n\n#6_fish type: lichen\nMC2_lichen_nodes <-as_tibble(MC2_lichen$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_lichen_edges <-as_tibble(MC2_lichen$links) %>%\n    relocate(7,8,6,5,1,2,9,3,4)\n\n#7_fish type: mackerel\nMC2_mackerel_nodes <-as_tibble(MC2_mackerel$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_mackerel_edges <-as_tibble(MC2_mackerel$links) %>%\n    relocate(6,7,5,4)\n\n#8_fish type: pollock\nMC2_pollock_nodes <-as_tibble(MC2_pollock$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_pollock_edges <-as_tibble(MC2_pollock$links) %>%\n    relocate(8,9,7,6)\n\n#9_fish type: salmon_wgl\nMC2_salmon_wgl_nodes <-as_tibble(MC2_salmon_wgl$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_salmon_wgl_edges <-as_tibble(MC2_salmon_wgl$links) %>%\n  relocate(7,8,6,5,1,2,9,3,4)\n\n#10_fish type: salmon\nMC2_salmon_nodes <-as_tibble(MC2_salmon$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_salmon_edges <-as_tibble(MC2_salmon$links) %>%\n  relocate(8,9,7,6)\n\n#11_fish type: shark\nMC2_shark_nodes <-as_tibble(MC2_shark$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_shark_edges <-as_tibble(MC2_shark$links) %>%\n    relocate(7,8,6,5,1,2,9,3,4)\n\n#12_fish type: tuna\nMC2_tuna_nodes <-as_tibble(MC2_tuna$nodes) %>%\n  select(id,dataset,shpcountry,rcvcountry)\nMC2_tuna_edges <-as_tibble(MC2_tuna$links) %>%\n  relocate(5,6,4,3)"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#concatenate-data-frame-from-bundles",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#concatenate-data-frame-from-bundles",
    "title": "Take Home Exercise 2",
    "section": "3.4 Concatenate Data frame from Bundles",
    "text": "3.4 Concatenate Data frame from Bundles\nAfter it has been converted to tibble data frame, the bundles are concatenated. Among the 12 files, there are 3 data frames which have 7 variables whereas the rest have 9 variables. As such, bind_rows() - a function from the dplyr package within the tidyverse is used.\nMoreover, the knitr: kable() function is used to display the results of the combined_edges.\n\n\nShow the code\n# concatenante the edges \ncombined_edges <- bind_rows(MC2_carp_edges,MC2_chub_mackerel_edges,\n                        MC2_cod2_edges,MC2_herring_edges,MC2_lichen_edges,\n                        MC2_pollock_edges,MC2_salmon_wgl_edges,\n                        MC2_salmon_edges,MC2_shark_edges, \n                        MC2_catfish_edges,MC2_mackerel_edges,MC2_tuna_edges)\n\n# concatenate the nodes \ncombined_nodes <- bind_rows(MC2_carp_nodes,MC2_catfish_nodes,\n                            MC2_chub_mackerel_nodes,MC2_cod2_nodes,\n                            MC2_herring_nodes, MC2_lichen_nodes,\n                            MC2_mackerel_nodes, MC2_pollock_nodes, \n                            MC2_salmon_wgl_nodes,MC2_salmon_nodes,\n                            MC2_shark_nodes, MC2_tuna_nodes)\n\n#output for dataframe using knitr:: kable\nkable(head(combined_edges), \"simple\")\n\n\n\n\n\nsource\ntarget\ndataset\ngenerated_by\narrivaldate\nhscode\nvalueofgoods_omu\nvolumeteu\nweightkg\n\n\n\n\nTshimbua GmbH & Co. KG\nCaracola del Sol Services\nMC2\ncarp\n2034-03-20\n80440\n15915\n0\n15720\n\n\nMarine Masterminds Dry dock\nPlaya de la Luna Incorporated\nMC2\ncarp\n2034-08-01\n940179\nNA\n0\n10795\n\n\nMarine Masterminds Dry dock\nSaltwater Supreme ОАО Forwading\nMC2\ncarp\n2034-11-27\n940161\nNA\n0\n6555\n\n\nMarine Masterminds Dry dock\nSaltwater Supreme ОАО Forwading\nMC2\ncarp\n2034-10-10\n940161\nNA\n0\n6675\n\n\nzhāng yú Ges.m.b.H. Solutions\nPortuguese Tuna Incorporated Marine\nMC2\ncarp\n2034-04-09\n40729\nNA\n15\n54775\n\n\nNile S.A. de C.V.\nCaracola del Sol Services\nMC2\ncarp\n2034-03-30\n700711\nNA\n0\n22430\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCatfish, Mackerel, and Tuna have 7 variables while other fishes have 9 variables. It is better to concatenate with the use of blind_rows instead of rbind() as the latter requires an exact match in the numbers of columns."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#creating-a-master-id-data-frame",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#creating-a-master-id-data-frame",
    "title": "Take Home Exercise 2",
    "section": "3.5 Creating a Master ID data frame",
    "text": "3.5 Creating a Master ID data frame\nMoving on, we would like to create a master ID data frame from the knowledge graph. It is unclear whether there are any missing source or target that are not reflected in the MC_challenge_nodes.\nThe code chunk below will identify if there are any missing id. If it exists in either columns, it will be appended back to the MC2_challenge_nodes data frame. A new column called trade_status is created to help identify the trade status of the company. !is.na() functions is used to check for values. If it is N/A in both columns, the trade status will be updated as Unknown.\nLikewise, we rename the id to label and create an id column through mutate and nrow which becomes an unique identifier to the label.\n\n\nShow the code\n#create new df and add new column called trade_status\nMC2_id_list_vis <- MC2_challenge_nodes %>%\n  rename(label = id) %>%\n  mutate(id = as.character(1:nrow(MC2_challenge_nodes)),\n    trade_status = case_when(\n    !is.na(shpcountry) & !is.na(rcvcountry) ~ \"Import & Export\",\n    !is.na(shpcountry) ~ \"Export\",\n    !is.na(rcvcountry) ~ \"Import\",\n    is.na(shpcountry) | is.na(rcvcountry) ~\"Unknown\"\n  )) %>%\n  filter(!is.na(trade_status))\n\n#reorder the columns \nMC2_id_list_vis <- MC2_id_list_vis %>%\n  select(id,label, trade_status,shpcountry, rcvcountry)\n\n#create similar list \nMC2_id_list <- MC2_challenge_nodes %>%\n  rename(label = id) %>%\n  mutate(\n    trade_status = case_when(\n    !is.na(shpcountry) & !is.na(rcvcountry) ~ \"Import & Export\",\n    !is.na(shpcountry) ~ \"Export\",\n    !is.na(rcvcountry) ~ \"Import\",\n    is.na(shpcountry) | is.na(rcvcountry) ~\"Unknown\"\n  )) \n\n#reorder the columns \nMC2_id_list <- MC2_id_list %>%\n  select(label,trade_status,shpcountry, rcvcountry)\n\n#create df to identify companies in target column that are not in the nodes \nID_target <- MC2_challenge_edges %>%\n  filter(!(target %in% MC2_id_list$label)) %>%\n  distinct(target) %>%\n  #rename to match names in nodes df\n  rename(id = target) %>%\n  #dummy columns are created to bind rows together\n  mutate(dataset = NA, shpcountry = NA, rcvcountry = NA)\n\n#create df to identify companies in source column that are not in the nodes \nID_source <- MC2_challenge_edges %>%\n  filter(!(source %in% MC2_id_list$label)) %>%\n  distinct(source) %>%\n  rename(id = source) %>%\n  mutate(dataset = NA, shpcountry = NA, rcvcountry = NA)\n\n#append the distinct companies into the nodes \nMC2_challenge_nodes <- MC2_challenge_nodes %>%\n  rbind(ID_target) %>%\n  rbind(ID_source)\n\n\nAs observed, all the companies are well stored in the MC2_challenge_nodes data frame.\n\n#output of ID nodes that are not in Master list\nnrow(ID_source)\n\n[1] 0\n\nnrow(ID_target)\n\n[1] 0"
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#data-wrangling",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#data-wrangling",
    "title": "Take Home Exercise 2",
    "section": "3.5 Data Wrangling",
    "text": "3.5 Data Wrangling\nAfter concatenating and creating a master ID data frame, adjustments are made to rectify the following:\n\narrivaldate is not in date format. [Revised through lubridate in the ymd format]\nhscode is not in chr format. [Revised from int]\ndate is not comprehensive. [Create new column called year]\nedge data frame does not have corresponding id to source and target. [Rename source and target to sourcelabel and targetlabel respectively. Thereafter, Left_join with master ID MC2_id_list_vis data frame to get the corresponding ID]\n\n\n\nShow the code\n#revise the data format for arrivaldate and hscode \nMC2_challenge_edges<- MC2_challenge_edges %>%\n  rename(sourcelabel = source, targetlabel = target) %>%\n  mutate(arrivaldate =ymd(arrivaldate),\n         hscode = as.character(hscode),\n         year = year(arrivaldate))\n\n#to append correspoinding id through left_join \nMC2_challenge_edges <- MC2_challenge_edges %>%\n  left_join(MC2_id_list_vis, by = c(\"sourcelabel\" = \"label\")) %>%\n  rename(source = id) %>%\n  left_join(MC2_id_list_vis, by = c(\"targetlabel\" = \"label\")) %>%\n  rename(target = id) %>%\n  relocate(10,14)\n\n#revised the same approach to the bundles \ncombined_edges_cleaned<- combined_edges %>%\n  mutate(arrivaldate =ymd(arrivaldate),\n         hscode = as.character(hscode))\n\n#output for dataframe using knitr:: kable\nkable(head(combined_edges_cleaned), \"simple\")\n\n\n\n\n\nsource\ntarget\ndataset\ngenerated_by\narrivaldate\nhscode\nvalueofgoods_omu\nvolumeteu\nweightkg\n\n\n\n\nTshimbua GmbH & Co. KG\nCaracola del Sol Services\nMC2\ncarp\n2034-03-20\n80440\n15915\n0\n15720\n\n\nMarine Masterminds Dry dock\nPlaya de la Luna Incorporated\nMC2\ncarp\n2034-08-01\n940179\nNA\n0\n10795\n\n\nMarine Masterminds Dry dock\nSaltwater Supreme ОАО Forwading\nMC2\ncarp\n2034-11-27\n940161\nNA\n0\n6555\n\n\nMarine Masterminds Dry dock\nSaltwater Supreme ОАО Forwading\nMC2\ncarp\n2034-10-10\n940161\nNA\n0\n6675\n\n\nzhāng yú Ges.m.b.H. Solutions\nPortuguese Tuna Incorporated Marine\nMC2\ncarp\n2034-04-09\n40729\nNA\n15\n54775\n\n\nNile S.A. de C.V.\nCaracola del Sol Services\nMC2\ncarp\n2034-03-30\n700711\nNA\n0\n22430\n\n\n\n\n\n\nDuplicates found [Retain for further analyses as the purchases might be broken down into small trade to avoid detection ]\n\n\n\nShow the code\n#check for duplicates \ndup <- (nrow(MC2_challenge_edges) - nrow(unique(MC2_challenge_edges)))\n#reformat output \ndup_reformat <- format(dup, big.mark=\",\")\n#print output\ndup_reformat\n\n\n[1] \"155,291\""
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#number-of-transactions-by-year-and-month",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#number-of-transactions-by-year-and-month",
    "title": "Take Home Exercise 2",
    "section": "4.1 Number of Transactions by Year and Month",
    "text": "4.1 Number of Transactions by Year and Month\nHeatmap is created to provide a graphical representation to the transactions. It uses a system of color-coding to represent different values. [RColorBrewer] package is used to include sequential palettes “Blues” showing progress from low to high (gradient).\nAs fishing might occurs on a seasonality basis, we created an additional column called month before grouping it by year and month. To create an interactive heatmap, data frame are transpose through pivot_wider before converting it to matrix with the as.matrix function. Thereafter, [heatmaply] package is used.\n\n\nShow the code\n#aggregate to determine transactions count by year and month \ntransaction_counts_by_year <- MC2_challenge_edges %>%\n  mutate(month = round(month(arrivaldate))) %>%\n  group_by(year, month) %>%\n  summarise(count = n())\n\n#transpose df by using pivot_wider\npivoted_data <- transaction_counts_by_year %>%\n  pivot_wider(names_from = year, values_from = count) %>%\n  #remove the month column\n  select(2:8)\n\n#convert pivoted_data into a matrix\nheatmap_data <- as.matrix(pivoted_data)\n\n#create interactive heatmap without dendrogram\nheatmaply(heatmap_data, dendrogram = \"none\",\n          xlab = \"Year\", ylab = \"Month\",\n          main = \"Number of Transactions by Year and Month\",\n          scale = \"none\",\n          grid_color = \"white\",\n          grid_width = 0.00001,\n          titleX = FALSE,\n          hide_colorbar =  FALSE,\n          label_names = c(\"Month:\", \"Year: \", \"No. of Transactions:\"),\n          fontsize_row = 10, fontsize_col = 10,\n          colors = \"Blues\",\n          labCol = colnames(heatmap_data),\n          labRow = rownames(heatmap_data),\n          plot_method = \"plotly\")\n\n\n\n\n\n\nObservations:\n\nOn a yearly basis, the volume of trade is decreasing at a decreasing rate. It peaks around 2028-2030 with the highest time period, occurring in 2030.\nMarch seems to be a period with low transactions. However, it reaches a record in Mar 2030, with the highest volume of transactions in the seven years time period."
  },
  {
    "objectID": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#trade-flow-of-company-with-above-30-transactions-in-mar-2023",
    "href": "Take-Home_Ex/Take_Home_Ex02/Take-Home_Ex02.html#trade-flow-of-company-with-above-30-transactions-in-mar-2023",
    "title": "Take Home Exercise 2",
    "section": "4.2 Trade flow of Company with above 30 transactions in Mar 2023",
    "text": "4.2 Trade flow of Company with above 30 transactions in Mar 2023\nNoting that Mar 2030 has a record of high volume, we would like to examine the trade flow of the Company in this time frame. We start off by creating a new edges and nodes data frame. The edges are created by aggregating it from the the master edges file MC2_challenge_edges.\nWe will be using the [dpylr] package to create MC2_2030_Mar_edges:\n\nmutate(): to add additional column called month\nfilter(): is used to filter for year = 2030 and month = 3\ngroup_by is used to aggregate it by hscode and year\nsummarize() is used to compute the weight and median_weight of goods\nfilter() is used to remove matching name in source and target and to filter for transactions with above 30 counts. This brings up to ~200 rows.\nrename() is used to change the title of the column\n\nThereafter, we create MC2_2030_Mar_nodes by filtering out the distinct ID that are in the source and label column from the master ID data frame, MC2_id_list_vis .\n\n\nShow the code\n#create edges df for transactions from Mar 2030\nMC2_2030_Mar_edges <- MC2_challenge_edges %>%\n  mutate(month = round(month(arrivaldate))) %>%\n  filter(year == \"2030\" & month ==\"3\") %>%\n  group_by(source, target, hscode) %>%\n  summarize(weight = n()) %>%\n  filter(source !=target) %>%\n  filter(weight >29) %>% #keep ~200 rows \n  rename(from = source, to = target) %>%\n  select(1,2,4,3) %>% #relocate weight to 3rd column \n  ungroup()\n\n#create nodes df for transactions from Mar 2030\nMC2_2030_Mar_nodes <- MC2_id_list_vis %>%\n  filter(id %in% MC2_2030_Mar_edges$from | id %in% MC2_2030_Mar_edges$to) %>%\n  distinct() \n\n\nIn the code chunk below, we compute the centrality between the nodes, by using the graph_from_data_frame function from the [igraph] package. As seen from the output below, the top row represents the ID of the companies while the bottom row represents their score. Given that the result of the betweenness centrality and closeness centrality are not significant, we will would look into the degree centrality.\n\n#create igraph object \ng <- graph_from_data_frame(d=MC2_2030_Mar_edges, \n                           vertices=MC2_2030_Mar_nodes, directed=TRUE) \n\n#compute betweeness centrality \nbetweenness_centrality <- betweenness(g)\nMC2_2030_Mar_nodes$betweenness_centrality <-\n  betweenness_centrality[as.character(MC2_2030_Mar_nodes$id)]\n\n#output for top results\nhead(sort(betweenness_centrality, decreasing=TRUE))\n\n 8  3  5  6  9 11 \n 6  0  0  0  0  0 \n\n\nAfter the data preparation, visNetwork is used to plot the plot the interactive network graph with the Fruchterman and Reingold layout. Additionally, the graph uses three colors tone from the diverging palettes scheme to color-code the nodes based on degree centrality. It ranges from red - yellow - blue.\n\n\nShow the code\n#compute degree centrality \ndegree_centrality <- degree(g)\nMC2_2030_Mar_nodes$degree_centrality <- \n  degree_centrality[as.character(MC2_2030_Mar_nodes$id)]\n\n#compute closeness centrality \ncloseness_centrality <- closeness(g, normalized=TRUE)\nMC2_2030_Mar_nodes$closeness_centrality <- \n  closeness_centrality[as.character(MC2_2030_Mar_nodes$id)]\n\n#add diverging palettes scheme to nodes based on degree centrality\ncolors <- colorRampPalette(brewer.pal(3, \"RdYlBu\"))(3) # use three colors \nMC2_2030_Mar_nodes <- MC2_2030_Mar_nodes %>%\n  mutate(shape=\"dot\", shadow=TRUE,  \n         title=trade_status, # hover for trade_status\n         label=label, # add labels on nodes\n         size=20, # set size of nodes\n         borderWidth=1, #set border width of nodes\n         color.background=colors[degree_centrality], #set color\n         color.border=\"grey\") #set border color \n\n#plot network graph \nvisNetwork(MC2_2030_Mar_nodes, MC2_2030_Mar_edges, \n            main =\"Trade flow of Company  \n           <br>with above 30 transactions in Mar 2023<br>\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE,\n             selectedBy =\"degree_centrality\") %>%\n  visEdges(arrows = \"to\") %>% #indicate direction \n  visLayout(randomSeed = 123) %>%\n  addFontAwesome(name = \"font-awesome\") %>% #add icon to network \n  visInteraction(dragNodes = FALSE, dragView = TRUE, \n                 zoomView = TRUE, navigationButtons = TRUE) #freeze network\n\n\n\n\n\n\n\n\n\n\n\n\nNote about visNetwork\n\n\n\n\n\nvisIgraphLayout is used to compute coordinates. In the example above, the Fruchterman and Reingold layout is used.\nvisOptions is an options for network visualization. We highlighted the nearest when clicking a node, a dropdown list for ID, a dropdown list by degree of centrality.\nvisEdges is edges options. We includes arrow to indicate direction.\nvisLayout is an layout options. randomSeed is included for the layout to remain the same every time.\naddFontAwesome is used to add icons to the network.\nvisInteraction is used for network visualization interaction.\nThe default setting as as follows:\n\ndragNodes : IF TRUE, nodes can be dragged around by user.\ndragView : If TRUE, view can be dragged around by user.\nzoomView : If TRUE, user can zoom in.\nnavigationButtons: If FALSE, navigation buttons are not on the network graph\n\n\n\n\nObservations:\n\nBlue nodes refer to a high degree of centrality. hǎi dǎn Corporation Wharf has the highest degree of 19, followed by Saltwater Supreme OAO forwarding with a score of 12.\nMajority of the Company have low degree of centrality and work exclusively with another counterpart. For companies in cluster, they generally have high degree of centrality and deals with companies with low degree of centrality (Orange nodes)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\npacman::p_load(rstatix,gt,patchwork,tidyverse,webshot2,png)\n\n\nImporting data\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualizing-statistical-graph-qq-plot",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualizing-statistical-graph-qq-plot",
    "title": "In-class Exercise 4",
    "section": "1) Visualizing statistical graph QQ Plot",
    "text": "1) Visualizing statistical graph QQ Plot\nThe quantile-quantile (q-q) plot is a graphical technique for determining if two data sets come from populations with a common distribution.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data,\n       aes(sample=ENGLISH)) +\n  stat_qq() +\n  stat_qq_line()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#combining-statistical-graph-and-analysis-table",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#combining-statistical-graph-and-analysis-table",
    "title": "In-class Exercise 4",
    "section": "2) Combining statistical graph and analysis table",
    "text": "2) Combining statistical graph and analysis table\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nqq <- ggplot(exam_data,\n       aes(sample=ENGLISH)) +\n  stat_qq() +\n  stat_qq_line()\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH) %>%\n  gt()\n\ntmp <-tempfile(fileext = \".png\")\ngtsave(sw_t,tmp)\ntable_png <- png::readPNG(tmp,\nnative= TRUE)\n\nqq + table_png"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "Using p_load() of pacman package to load the required libraries\n\n\npacman :: p_load (jsonlite, tidygraph, ggraph, visNetwork, tidyverse)\n\n\nImporting data\n\n\nMC1 <- fromJSON(\"data/MC1.json\")\n\n\n\n\nMC1_nodes <-as_tibble(MC1$nodes) %>%\n  select(id,type, country)\n\n\nMC1_edges <-as_tibble(MC1$links) %>%\n  select(source,target,type,weight,key)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#refer-to-hands-on-exercise-5",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#refer-to-hands-on-exercise-5",
    "title": "In-Class Exercise 5",
    "section": "Refer to Hands-on Exercise 5",
    "text": "Refer to Hands-on Exercise 5\n\nWrangling Time\n\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nWrangling attributes\n\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n\nUsing tbl_graph() to build tidygraph data model\n\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nChanging the active object\n\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\nPlotting basic network graph\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-Class Exercise 7",
    "section": "",
    "text": "Getting started\n\nUsing p_load() of pacman package to load the required libraries\n\n\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\nImporting data\n\n\naverp <- read_csv(\"data/AVERP.csv\") %>%\n  mutate(`Date` = dmy(`Date`)) #to overwrite data in case system differs\n\n\n\n1. Plotting the horizon graph\n\naverp %>% \n  filter(Date >= \"2018-01-01\") %>%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') + \n  #everything from above will give you the horizon graph then you tidy it up\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 4, angle = 0, hjust = 0),   #trial and error for best fit \n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=6),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "Using p_load() of pacman package to load tidyverse on\n\n\npacman:: p_load(tidyverse) \n\n\nImporting data\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#horizontal-bar-graph",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#horizontal-bar-graph",
    "title": "In-class Exercise 1",
    "section": "1) Horizontal Bar Graph",
    "text": "1) Horizontal Bar Graph\nChanging the colors of plot panel background of theme_minimal() to light blue and the color of grid lines to white.\n\nOutput:\n\nggplot(data= exam_data,\n       aes(x = RACE)) +\n       geom_bar() +\n       coord_flip() +\n       theme_minimal() +\n       theme(panel.background = element_rect(fill = 'lightblue') ,\n       panel.grid.minor=element_line(colour=\"white\"),\n       panel.grid.major=element_line(colour=\"white\")) +\n       ggtitle(\"Horizontal Bar Chart: \\nLight Blue theme and White grid lines \") +  \n       theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#vertical-bar-graph",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#vertical-bar-graph",
    "title": "In-class Exercise 1",
    "section": "2) Vertical Bar Graph",
    "text": "2) Vertical Bar Graph\nWith reference to the critics on the earlier slide, create a makeover looks similar to the figure on the right.\n\nOutput 1:\n\nggplot(data= exam_data,\n      aes(x = fct_infreq(RACE))) +\n      geom_bar() +\n      xlab(\"Race\") +\n      ylab(\"No.of\\nPupils\") +\n      ylim(0,220) +\n      geom_text(aes(label = paste(..count..,\",\", scales::percent(..count../sum(..count..),accuracy = 0.1))), \n      stat= \"count\", vjust = -0.5) +\n      ggtitle(\"Vertical Bar Chart: \\nSorted Frequency + Labelling \") +\n      theme(plot.title = element_text(hjust = 0.5))\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\nOutput 2: Forcats Package.:\n\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#histogram",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#histogram",
    "title": "In-class Exercise 1",
    "section": "3) Histogram",
    "text": "3) Histogram\n\nAdding mean and median lines on the histogram plot.\nChange fill color and line color\n\n\nOutput:\n\nggplot(data= exam_data,\n       aes(x = MATHS)) +\n       geom_histogram(color=\"black\",fill=\"light blue\",bins = 30) +\n       geom_vline(aes(xintercept=mean(MATHS)),\n            color=\"red\", linetype=\"dashed\", size=1) +\n       geom_vline(aes(xintercept=median(MATHS)),\n            color=\"black\", linetype=\"dashed\", size=1) +\n       ggtitle(\"Histogram: \\nAdd lines and color \") +  \n       theme(plot.title = element_text(hjust = 0.5))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n3.1) By Gender\n\nThe background histograms show the distribution of English scores for all pupils.\n\n\nOutput:\n\nd <- exam_data   \nd_bg <- d[, -3] \n\nggplot(d, aes(x = ENGLISH)) +\n       geom_histogram (data= d_bg, bins=30, alpha = 0.2) +\n       geom_histogram (bins=30, color = 'black') +\n       facet_wrap(~ GENDER) + \n       theme_bw()       \n\n\n\n\n\nd <- exam_data   \nd_bg <- d[, -3]  \n\nggplot(d, aes(x = ENGLISH, fill = GENDER)) +\n  geom_histogram(data = d_bg, fill = \"grey\", alpha = .5) +\n  geom_histogram(colour = \"black\") +\n  facet_wrap(~ GENDER) +\n  theme_bw() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nd <- exam_data   \nd_bg <- d[, -3] \n\nggplot(data = exam_data, aes(x = ENGLISH, fill= GENDER, )) +\n    geom_histogram(bins = 30) +\n    facet_wrap(~ GENDER) +\n    guides(fill = FALSE) \n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#scatterplot",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#scatterplot",
    "title": "In-class Exercise 1",
    "section": "4) Scatterplot",
    "text": "4) Scatterplot\n\nThe scatterplot show the relationship between English and Maths for all pupils.\n\n\nOutput:\n\nggplot(data = exam_data, \n        aes (x= MATHS, y= ENGLISH)) +\n        geom_point() +\n        geom_hline(yintercept=50, linetype=\"dashed\", color = \"darkgrey\") +\n        geom_vline(xintercept=50, linetype=\"dashed\", color = \"darkgrey\") +\n        coord_cartesian(xlim=c(0,100), ylim=c(0,100))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-Class Exercise 6",
    "section": "",
    "text": "Getting started\n\nUsing p_load() of pacman package to load the required libraries\n\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  }
]