library(shiny) library(bslib) library(tidyverse) library(jsonlite) library(tidytext) library(wordcloud2) library(tidytext) library(shiny.semantic) library(shinydashboard) library(shinycssloaders)

```{r}
pacman::p_load(jsonlite, tidygraph, ggraph, 
               visNetwork, graphlayouts, ggforce, 
               skimr, tidytext, tidyverse,ldatuning)
options(scipen = 999) 
```

#importing the data

```{r}
MC3_challenge <- fromJSON("data/MC3.json")

#extracting edges 
MC3_edges <-as_tibble(MC3_challenge$links) %>%
  distinct() %>%
  mutate(source = as.character(source),
         target = as.character(target),
         type = as.character(type)) %>%
  group_by(source,target, type) %>%
  summarise(weights = n()) %>%
  filter (source != target) %>%
  ungroup()

#extrading nodes 
MC3_nodes <-as_tibble(MC3_challenge$nodes) %>%
  mutate(country = as.character(country),
         id = as.character(id),
         product_services = as.character(product_services),
         revenue_omu = as.numeric(as.character(revenue_omu)),
         type = as.character(type)) %>%
  select(id,country,type,revenue_omu,product_services)

#default masterlist 
id1 <- MC3_edges %>%
  select(source) %>%
  rename(id = source)
id2 <- MC3_edges %>%
  select(target) %>%
  rename(id = target)
MC3_nodes_master <- rbind(id1, id2) %>%
  distinct() %>%
  left_join(MC3_nodes,
            unmatched = "drop")

#create new node df to include id number
MC3_nodes_Masterlist <- MC3_nodes_master %>%
  select(id) %>%
  distinct() %>%
  rename(label = id) %>%
  ungroup()

#add ID to nodes dataframe
MC3_masternodes <- MC3_nodes_Masterlist %>%
  mutate(id = as.character(1:nrow(MC3_nodes_Masterlist))) %>%
  relocate(id,label) %>%
  ungroup()

#to append correspoinding id through left_join 
MC3_edges_addID <- MC3_edges %>%
  rename(sourcelabel = source, targetlabel = target) %>%
  left_join(MC3_masternodes, by = c("sourcelabel" = "label")) %>%
  rename(source = id) %>%
  left_join(MC3_masternodes, by = c("targetlabel" = "label")) %>%
  rename(target = id) %>%
  relocate(source,target)

```

```{r}
#word related code from this line
#unnest words
token_nodes <- MC3_nodes %>%
  unnest_tokens(word, product_services)

#remove stop_words
stopwords_removed <- token_nodes %>% 
  anti_join(stop_words)

#remove generic words 
remove_characters <- c("character", "0","unknown","products","services",
                       "including", "source", "offers","range", "related")

#create dataframe of each word with frequency 
stopwords_removed_freq <- stopwords_removed %>%
  filter(!word %in% remove_characters) %>%
  group_by(word) %>%
  summarize(count = n()) %>%
  arrange(desc(count)) %>%
  ungroup()
```

```{r}
library(topicmodels)

token_nodes %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
      labs(x = "Count",
      y = "Unique words",
      title = "Count of unique words found in product_services field")
```

```{r}
token_nodes$word[token_nodes$word == "character"] <- "NA"
token_nodes$word[token_nodes$word == "0"] <- "NA"

#remove stop_words
stopwords_removed <- token_nodes %>% 
  anti_join(stop_words) %>%
  filter(!word %in% c("NA", "unknown", "products"))

dim(stopwords_removed)

stopwords_removed %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
      labs(x = "Count",
      y = "Unique words",
      title = "Count of unique words found in product_services field")

```

```{r}
# using as.matrix()
MC3_text <- stopwords_removed %>%
  count(id, word) %>%  # count each word used in each identified review 
  cast_dtm(id, word, n) %>%  # use the word counts by reviews  to create a DTM
  as.matrix()

# create models with different number of topics
result <- ldatuning::FindTopicsNumber(
  MC3_text,
  topics = seq(from = 2, to = 20, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  verbose = TRUE
)

FindTopicsNumber_plot(result)


```

```{r}

# number of topics
K <- 12
# set random number generator seed
set.seed(1234)
# compute the LDA model, inference via 1000 iterations of Gibbs sampling
topicModel <- LDA(MC3_text, K, method="Gibbs", control=list(iter = 500, verbose = 25))

lda_topics <- topicModel %>%
  tidy(matrix = "beta")
```

```{r}
lda_topics <- LDA(
  MC3_text,
  k = 12,
  method = "Gibbs",
  control = list(seed=42)
  ) %>%
  tidy(matrix = "beta")

word_probs <- lda_topics %>%
  group_by(topic) %>%
  top_n(15, beta) %>%
  ungroup() %>%
  mutate(term2 = fct_reorder(term, beta))

ggplot(
  word_probs,
  aes(term2, beta, fill=as.factor(topic))
  ) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

```


```{r}
library(plotly)

ggplot( word_probs, 
        aes(term2, beta, fill=as.factor(topic)) ) + 
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

p <- plot_ly(data = word_probs, 
             x = ~beta, y = ~term2, type = "bar", color = ~as.factor(topic),
             showlegend = FALSE ) 
p

```
